{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_noclean.csv')\n",
    "test_data = pd.read_csv('./test_noclean.csv')\n",
    "\n",
    "y_train = train_data.loc[:,'price']\n",
    "train_data = train_data.drop(columns='price')\n",
    "num_features = len(train_data.columns)\n",
    "features = list(train_data.columns[2:num_features])\n",
    "X_train = train_data.loc[:,features]\n",
    "\n",
    "features = list(test_data.columns[2:num_features])\n",
    "\n",
    "X_test = test_data.loc[:,features]\n",
    "test_labels = test_data.loc[:,'id']\n",
    "\n",
    "test_labels = test_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, y_train, learn, max_depth, num_class, num_leaves, min_data_in_leaf, rounds):\n",
    "    params={}\n",
    "    params['learning_rate']=0.03\n",
    "    params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
    "    params['objective']='multiclass' #Multi-class target feature\n",
    "    params['metric']='multi_error' #metric for multi-class\n",
    "    params['max_depth']=max_depth\n",
    "    params['num_class']=num_class\n",
    "    params['num_leaves']=num_leaves\n",
    "    clf=lgb.train(params,d_train,rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 1500],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [10, 15,20,25],\n",
    "    'num_leaves': [10, 20, 30, 40, 50],\n",
    "    'reg_lambda': [0.2, 0.5, 0.8, 1, 1.1],\n",
    "    'reg_alpha' : [0.2, 0.5, 0.8, 1, 1.1], \n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20], \n",
    "    'min_data_in_leaf': [15, 25, 30, 40],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', metric='multi_error')\n",
    "rsearch = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_grid, cv=kf, n_iter = 100, n_jobs = -1, verbose=10)\n",
    "lgb_model = rsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7} 0.5615135310322475\n"
     ]
    }
   ],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n",
    "#THIS IS FOR THE RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1593 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1709 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1829 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed: 34.1min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000, 2500, 3000],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'max_depth': [10, 15,20,25],\n",
    "    'num_leaves': [ 30],\n",
    "    'reg_lambda': [ 1.1, 1, 1.2],\n",
    "    'reg_alpha' : [ 0.8], \n",
    "    'min_split_gain': [0.4],\n",
    "    'subsample': [ 0.9, 1],\n",
    "    'subsample_freq': [20], \n",
    "    'min_data_in_leaf': [15, 10, 20],\n",
    "    'learning_rate': [0.01, 0.005]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', metric='multi_error')\n",
    "rsearch = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_grid, cv=kf, n_iter = 1000, n_jobs = -1, verbose=10)\n",
    "lgb_model = rsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.2, 'reg_alpha': 0.8, 'num_leaves': 30, 'n_estimators': 2000, 'min_split_gain': 0.4, 'min_data_in_leaf': 10, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7} 0.5563482417760492\n"
     ]
    }
   ],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5386996904024768\n",
      "0.5340909090909091\n",
      "0.5650826446280992\n",
      "0.5692148760330579\n",
      "0.5671487603305785\n",
      "0.5475206611570248\n",
      "0.5671487603305785\n",
      "0.5650826446280992\n",
      "0.5392561983471075\n",
      "0.5661157024793388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.2, 'reg_alpha': 0.8, 'num_leaves': 30, 'n_estimators': 2000, 'min_split_gain': 0.4, 'min_data_in_leaf': 10, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5583075335397317\n",
      "0.5692148760330579\n",
      "0.5847107438016529\n",
      "0.5557851239669421\n",
      "0.5805785123966942\n",
      "0.5485537190082644\n",
      "0.5247933884297521\n",
      "0.5423553719008265\n",
      "0.5299586776859504\n",
      "0.5671487603305785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 30, 'n_estimators': 3000, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5490196078431373\n",
      "0.5413223140495868\n",
      "0.5712809917355371\n",
      "0.5609504132231405\n",
      "0.5423553719008265\n",
      "0.5599173553719008\n",
      "0.5547520661157025\n",
      "0.5568181818181818\n",
      "0.5599173553719008\n",
      "0.5712809917355371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 1.2, 'num_leaves': 40, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 25, 'max_depth': 20, 'colsample_bytree': 0.7}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1519\n",
      "[LightGBM] [Info] Number of data points in the train set: 9681, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -1.385985\n",
      "[LightGBM] [Info] Start training from score -1.388052\n",
      "[LightGBM] [Info] Start training from score -1.367568\n",
      "[LightGBM] [Info] Start training from score -1.403905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "\n",
    "best_param1 = {'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 1.2, 'num_leaves': 40, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 25, 'max_depth': 20, 'colsample_bytree': 0.7}\n",
    "d_train=lgb.Dataset(X, y)\n",
    "clf=lgb.train(best_param1,d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8393760975105877\n"
     ]
    }
   ],
   "source": [
    "y_pred1=clf.predict(X)\n",
    "y_pred1 = [np.argmax(line) for line in y_pred1]\n",
    "print(accuracy_score(y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.63501347e-16 1.65708195e-01 5.21646525e-01 2.54137479e-01\n",
      "  5.85078004e-02]\n",
      " [9.88058645e-16 6.23022411e-02 3.79039465e-01 4.62610231e-01\n",
      "  9.60480631e-02]\n",
      " [9.40101224e-16 2.29830443e-01 4.57659098e-01 2.62552010e-01\n",
      "  4.99584497e-02]\n",
      " ...\n",
      " [9.69967917e-16 7.50665617e-02 2.24979721e-01 4.05296374e-01\n",
      "  2.94657343e-01]\n",
      " [3.57829217e-16 9.08182000e-01 4.16185959e-02 3.26919409e-02\n",
      "  1.75074634e-02]\n",
      " [1.39995573e-15 1.31422473e-01 3.79822158e-01 3.36081396e-01\n",
      "  1.52673973e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(line) for line in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame\n",
    "test_labels['price'] = y_pred\n",
    "\n",
    "test_labels['price'] = test_labels['price'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13196</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>12921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>7174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>9240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>11663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  price\n",
       "0      7715      2\n",
       "1     13196      3\n",
       "2     13194      2\n",
       "3      4673      2\n",
       "4     11325      2\n",
       "...     ...    ...\n",
       "4144  12921      2\n",
       "4145   7174      1\n",
       "4146   9240      3\n",
       "4147  11663      1\n",
       "4148   4513      2\n",
       "\n",
       "[4149 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(r'./submission8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "labels = pd.read_csv('./submission7.csv')\n",
    "y_pred = labels.loc[:,'price']\n",
    "plt.figure()\n",
    "plt.hist(y_pred)\n",
    "plt.title(\"Light GBM Predictions\")\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
