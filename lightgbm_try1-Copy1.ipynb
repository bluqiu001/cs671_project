{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_noclean3.csv')\n",
    "test_data = pd.read_csv('./test_noclean3.csv')\n",
    "\n",
    "y_train = train_data.loc[:,'price']\n",
    "train_data = train_data.drop(columns='price')\n",
    "num_features = len(train_data.columns)\n",
    "features = list(train_data.columns[2:num_features])\n",
    "X_train = train_data.loc[:,features]\n",
    "\n",
    "features = list(test_data.columns[2:num_features])\n",
    "\n",
    "X_test = test_data.loc[:,features]\n",
    "test_labels = test_data.loc[:,'id']\n",
    "\n",
    "test_labels = test_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, y_train, learn, max_depth, num_class, num_leaves, min_data_in_leaf, rounds):\n",
    "    params={}\n",
    "    params['learning_rate']=0.03\n",
    "    params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
    "    params['objective']='multiclass' #Multi-class target feature\n",
    "    params['metric']='multi_error' #metric for multi-class\n",
    "    params['max_depth']=max_depth\n",
    "    params['num_class']=num_class\n",
    "    params['num_leaves']=num_leaves\n",
    "    clf=lgb.train(params,d_train,rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1593 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1709 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1829 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2081 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2146 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2213 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2349 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2489 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2633 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2706 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2781 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2856 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2933 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3010 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3089 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3249 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3330 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3413 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3496 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3581 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3666 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3753 tasks      | elapsed: 41.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3929 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed: 44.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4109 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4200 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4293 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4386 tasks      | elapsed: 47.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4481 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4673 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4770 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4869 tasks      | elapsed: 52.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4968 tasks      | elapsed: 53.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5069 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5170 tasks      | elapsed: 55.4min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [10, 15,20,25],\n",
    "    'num_leaves': [10, 20, 30, 40, 50],\n",
    "    'reg_lambda': [0.2, 0.5, 0.8, 1, 1.1, 1.2],\n",
    "    'reg_alpha' : [0.2, 0.5, 0.8, 1, 1.1, 1.2], \n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1],\n",
    "    'subsample_freq': [20], \n",
    "    'min_data_in_leaf': [15, 25, 30, 40],\n",
    "    'learning_rate': [0.005, 0.01, 0.05, 0.1]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', metric='multi_error')\n",
    "rsearch = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_grid, cv=kf, n_iter = 1000, n_jobs = -1, verbose=10)\n",
    "lgb_model = rsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 25, 'learning_rate': 0.01, 'colsample_bytree': 0.8} 0.5570704227754608\n"
     ]
    }
   ],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 40, 'n_estimators': 1500, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.7} 0.559755840135097\n"
     ]
    }
   ],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n",
    "#THIS IS FOR THE RANDOM SEARCH WITH 100 CANDIATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000, 2500, 3000],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'max_depth': [10, 15,20,25],\n",
    "    'num_leaves': [ 30],\n",
    "    'reg_lambda': [ 1.1, 1, 1.2],\n",
    "    'reg_alpha' : [ 0.8], \n",
    "    'min_split_gain': [0.4],\n",
    "    'subsample': [ 0.9, 1],\n",
    "    'subsample_freq': [20], \n",
    "    'min_data_in_leaf': [15, 10, 20],\n",
    "    'learning_rate': [0.01, 0.005]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', metric='multi_error')\n",
    "rsearch = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_grid, cv=kf, n_iter = 1000, n_jobs = -1, verbose=10)\n",
    "lgb_model = rsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5748194014447885\n",
      "0.5382231404958677\n",
      "0.5547520661157025\n",
      "0.5547520661157025\n",
      "0.5537190082644629\n",
      "0.5516528925619835\n",
      "0.5692148760330579\n",
      "0.5547520661157025\n",
      "0.5351239669421488\n",
      "0.5805785123966942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 40, 'n_estimators': 1500, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56656346749226\n",
      "0.5402892561983471\n",
      "0.5702479338842975\n",
      "0.5557851239669421\n",
      "0.5867768595041323\n",
      "0.5733471074380165\n",
      "0.5464876033057852\n",
      "0.5175619834710744\n",
      "0.5568181818181818\n",
      "0.5568181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 25, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 1.2, 'num_leaves': 40, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 25, 'max_depth': 20, 'colsample_bytree': 0.7}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 0.8, 'num_leaves': 40, 'n_estimators': 1500, 'min_split_gain': 0.4, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "\n",
    "best_param1 = {'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 1.2, 'num_leaves': 40, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 25, 'max_depth': 20, 'colsample_bytree': 0.7}\n",
    "d_train=lgb.Dataset(X, y)\n",
    "clf=lgb.train(best_param,d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=clf.predict(X)\n",
    "y_pred1 = [np.argmax(line) for line in y_pred1]\n",
    "print(accuracy_score(y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(line) for line in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame\n",
    "test_labels['price'] = y_pred\n",
    "\n",
    "test_labels['price'] = test_labels['price'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(r'./submission8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [8,10,20],\n",
    "    'num_leaves': [15, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', learning_rate=0.01, metric='multi_error')\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=kf, verbose=2, n_jobs=-1)\n",
    "lgb_model = gsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
