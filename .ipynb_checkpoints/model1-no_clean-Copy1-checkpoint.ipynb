{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data here \n",
    "\n",
    "train_data = pd.read_csv('./train_noclean.csv')\n",
    "test_data = pd.read_csv('./test_noclean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   minimum_nights  number_of_reviews  last_review  reviews_per_month  \\\n",
      "0               1                170          205               2.48   \n",
      "1               1                 11          197               0.57   \n",
      "2               3                  2         1911               0.08   \n",
      "3               2                  1         1911               0.13   \n",
      "4               2                 31         1912               1.54   \n",
      "\n",
      "   calculated_host_listings_count  availability_365  host_since  \\\n",
      "0                               4               346          13   \n",
      "1                               1                 0          14   \n",
      "2                              19               360          17   \n",
      "3                               1               267          19   \n",
      "4                               5               365          15   \n",
      "\n",
      "   host_is_superhost  bathrooms  bedrooms  ...  Da_hood_Villa Urquiza  \\\n",
      "0              False        1.0         0  ...                      0   \n",
      "1              False        1.0         1  ...                      0   \n",
      "2               True        1.0         0  ...                      0   \n",
      "3               True        1.0         1  ...                      0   \n",
      "4              False        1.0         1  ...                      0   \n",
      "\n",
      "   Da_hood_Villa del Parque  Cancel_flexible  Cancel_moderate  \\\n",
      "0                         0                0                0   \n",
      "1                         0                0                1   \n",
      "2                         0                0                1   \n",
      "3                         0                1                0   \n",
      "4                         0                0                1   \n",
      "\n",
      "   Cancel_strict_14_with_grace_period  Cancel_super_strict_30  \\\n",
      "0                                   1                       0   \n",
      "1                                   0                       0   \n",
      "2                                   0                       0   \n",
      "3                                   0                       0   \n",
      "4                                   0                       0   \n",
      "\n",
      "   Room_Entire home/apt  Room_Hotel room  Room_Private room  Room_Shared room  \n",
      "0                     1                0                  0                 0  \n",
      "1                     0                0                  1                 0  \n",
      "2                     1                0                  0                 0  \n",
      "3                     1                0                  0                 0  \n",
      "4                     1                0                  0                 0  \n",
      "\n",
      "[5 rows x 69 columns]\n",
      "(9681, 69)\n",
      "(4149, 69)\n",
      "0       2\n",
      "1       1\n",
      "2       3\n",
      "3       2\n",
      "4       3\n",
      "       ..\n",
      "9676    4\n",
      "9677    4\n",
      "9678    3\n",
      "9679    3\n",
      "9680    1\n",
      "Name: price, Length: 9681, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = train_data.loc[:,'price']\n",
    "train_data = train_data.drop(columns='price')\n",
    "num_features = len(train_data.columns)\n",
    "features = list(train_data.columns[2:num_features])\n",
    "X_train = train_data.loc[:,features]\n",
    "\n",
    "features = list(test_data.columns[2:num_features])\n",
    "\n",
    "X_test = test_data.loc[:,features]\n",
    "test_labels = test_data.loc[:,'id']\n",
    "print(X_train.head(5))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train)\n",
    "test_labels = test_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_nights                     48\n",
      "number_of_reviews                 248\n",
      "last_review                        82\n",
      "reviews_per_month                 504\n",
      "calculated_host_listings_count     47\n",
      "                                 ... \n",
      "Cancel_super_strict_30              2\n",
      "Room_Entire home/apt                2\n",
      "Room_Hotel room                     2\n",
      "Room_Private room                   2\n",
      "Room_Shared room                    2\n",
      "Length: 69, dtype: int64\n",
      "16    1550\n",
      "15    1269\n",
      "14    1217\n",
      "18    1171\n",
      "17    1085\n",
      "19     988\n",
      "13     888\n",
      "12     792\n",
      "11     481\n",
      "10     138\n",
      "20      79\n",
      "9       22\n",
      "8        1\n",
      "Name: host_since, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.nunique())\n",
    "print(X_train['host_since'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, y_train, dtest, max_depth, n, eta, gamma):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    param = {'max_depth':max_depth, 'objective':'multi:softmax', 'eta':eta, 'gamma':gamma, 'num_class':5}\n",
    "    num_round = n\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "[0]\teval-merror:0.55005\ttrain-merror:0.56876\n",
      "[1]\teval-merror:0.55005\ttrain-merror:0.56876\n",
      "[2]\teval-merror:0.54180\ttrain-merror:0.54637\n",
      "[3]\teval-merror:0.54180\ttrain-merror:0.54637\n",
      "[4]\teval-merror:0.54180\ttrain-merror:0.54637\n",
      "[5]\teval-merror:0.54902\ttrain-merror:0.54614\n",
      "[6]\teval-merror:0.54283\ttrain-merror:0.54637\n",
      "[7]\teval-merror:0.54902\ttrain-merror:0.54614\n",
      "[8]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[9]\teval-merror:0.54902\ttrain-merror:0.54614\n",
      "[10]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[11]\teval-merror:0.54902\ttrain-merror:0.54614\n",
      "[12]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[13]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[14]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[15]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[16]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[17]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[18]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[19]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[20]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[21]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[22]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[23]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[24]\teval-merror:0.56553\ttrain-merror:0.53593\n",
      "[25]\teval-merror:0.55418\ttrain-merror:0.52778\n",
      "[26]\teval-merror:0.55418\ttrain-merror:0.52778\n",
      "[27]\teval-merror:0.54283\ttrain-merror:0.51963\n",
      "[28]\teval-merror:0.54283\ttrain-merror:0.51963\n",
      "[29]\teval-merror:0.54283\ttrain-merror:0.51974\n",
      "[30]\teval-merror:0.54283\ttrain-merror:0.51974\n",
      "[31]\teval-merror:0.54283\ttrain-merror:0.51974\n",
      "[32]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[33]\teval-merror:0.54283\ttrain-merror:0.51974\n",
      "[34]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[35]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[36]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[37]\teval-merror:0.54180\ttrain-merror:0.51860\n",
      "[38]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[39]\teval-merror:0.54180\ttrain-merror:0.51860\n",
      "[40]\teval-merror:0.54180\ttrain-merror:0.51860\n",
      "[41]\teval-merror:0.54180\ttrain-merror:0.51860\n",
      "[42]\teval-merror:0.54283\ttrain-merror:0.51951\n",
      "[43]\teval-merror:0.54180\ttrain-merror:0.51871\n",
      "[44]\teval-merror:0.54180\ttrain-merror:0.51871\n",
      "[45]\teval-merror:0.54180\ttrain-merror:0.51871\n",
      "[46]\teval-merror:0.54180\ttrain-merror:0.51871\n",
      "[47]\teval-merror:0.54180\ttrain-merror:0.51860\n",
      "[48]\teval-merror:0.54180\ttrain-merror:0.51894\n",
      "[49]\teval-merror:0.54180\ttrain-merror:0.51882\n",
      "[50]\teval-merror:0.54180\ttrain-merror:0.51882\n",
      "[51]\teval-merror:0.54180\ttrain-merror:0.51882\n",
      "[52]\teval-merror:0.54180\ttrain-merror:0.51882\n",
      "[53]\teval-merror:0.54180\ttrain-merror:0.51882\n",
      "[54]\teval-merror:0.54283\ttrain-merror:0.51882\n",
      "[55]\teval-merror:0.54283\ttrain-merror:0.51882\n",
      "[56]\teval-merror:0.54283\ttrain-merror:0.51882\n",
      "[57]\teval-merror:0.54386\ttrain-merror:0.51825\n",
      "[58]\teval-merror:0.54386\ttrain-merror:0.51814\n",
      "[59]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[60]\teval-merror:0.54283\ttrain-merror:0.51871\n",
      "[61]\teval-merror:0.54386\ttrain-merror:0.51814\n",
      "[62]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[63]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[64]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[65]\teval-merror:0.54386\ttrain-merror:0.51928\n",
      "[66]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[67]\teval-merror:0.54386\ttrain-merror:0.51905\n",
      "[68]\teval-merror:0.54386\ttrain-merror:0.51905\n",
      "[69]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[70]\teval-merror:0.54386\ttrain-merror:0.51837\n",
      "[71]\teval-merror:0.54386\ttrain-merror:0.51802\n",
      "[72]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[73]\teval-merror:0.54386\ttrain-merror:0.51860\n",
      "[74]\teval-merror:0.54386\ttrain-merror:0.51848\n",
      "[75]\teval-merror:0.54386\ttrain-merror:0.51802\n",
      "[76]\teval-merror:0.54386\ttrain-merror:0.51722\n",
      "[77]\teval-merror:0.54180\ttrain-merror:0.51779\n",
      "[78]\teval-merror:0.54180\ttrain-merror:0.51722\n",
      "[79]\teval-merror:0.53973\ttrain-merror:0.51641\n",
      "[80]\teval-merror:0.53973\ttrain-merror:0.51630\n",
      "[81]\teval-merror:0.53973\ttrain-merror:0.51584\n",
      "[82]\teval-merror:0.54076\ttrain-merror:0.51596\n",
      "[83]\teval-merror:0.53457\ttrain-merror:0.51251\n",
      "[84]\teval-merror:0.53457\ttrain-merror:0.51182\n",
      "[85]\teval-merror:0.53148\ttrain-merror:0.51102\n",
      "[86]\teval-merror:0.53457\ttrain-merror:0.50849\n",
      "[87]\teval-merror:0.53457\ttrain-merror:0.50861\n",
      "[88]\teval-merror:0.53457\ttrain-merror:0.50861\n",
      "[89]\teval-merror:0.53457\ttrain-merror:0.50838\n",
      "[90]\teval-merror:0.53457\ttrain-merror:0.50861\n",
      "[91]\teval-merror:0.53044\ttrain-merror:0.50780\n",
      "[92]\teval-merror:0.53044\ttrain-merror:0.50689\n",
      "[93]\teval-merror:0.53148\ttrain-merror:0.50769\n",
      "[94]\teval-merror:0.53148\ttrain-merror:0.50712\n",
      "[95]\teval-merror:0.53148\ttrain-merror:0.50746\n",
      "[96]\teval-merror:0.52941\ttrain-merror:0.50597\n",
      "[97]\teval-merror:0.52941\ttrain-merror:0.50597\n",
      "[98]\teval-merror:0.52941\ttrain-merror:0.50528\n",
      "[99]\teval-merror:0.52632\ttrain-merror:0.50562\n",
      "[100]\teval-merror:0.52735\ttrain-merror:0.50551\n",
      "[101]\teval-merror:0.52735\ttrain-merror:0.50494\n",
      "[102]\teval-merror:0.52735\ttrain-merror:0.50367\n",
      "[103]\teval-merror:0.52632\ttrain-merror:0.50367\n",
      "[104]\teval-merror:0.52735\ttrain-merror:0.50448\n",
      "[105]\teval-merror:0.52735\ttrain-merror:0.50459\n",
      "[106]\teval-merror:0.52528\ttrain-merror:0.50264\n",
      "[107]\teval-merror:0.52838\ttrain-merror:0.50298\n",
      "[108]\teval-merror:0.52632\ttrain-merror:0.50218\n",
      "[109]\teval-merror:0.52425\ttrain-merror:0.50252\n",
      "[110]\teval-merror:0.52941\ttrain-merror:0.50230\n",
      "[111]\teval-merror:0.52941\ttrain-merror:0.50218\n",
      "[112]\teval-merror:0.52941\ttrain-merror:0.50207\n",
      "[113]\teval-merror:0.53044\ttrain-merror:0.50172\n",
      "[114]\teval-merror:0.52941\ttrain-merror:0.50172\n",
      "[115]\teval-merror:0.52838\ttrain-merror:0.50264\n",
      "[116]\teval-merror:0.52941\ttrain-merror:0.50207\n",
      "[117]\teval-merror:0.52941\ttrain-merror:0.50230\n",
      "[118]\teval-merror:0.52941\ttrain-merror:0.50241\n",
      "[119]\teval-merror:0.52941\ttrain-merror:0.50230\n",
      "[120]\teval-merror:0.52838\ttrain-merror:0.50195\n",
      "[121]\teval-merror:0.52941\ttrain-merror:0.50103\n",
      "[122]\teval-merror:0.52838\ttrain-merror:0.50103\n",
      "[123]\teval-merror:0.52941\ttrain-merror:0.50103\n",
      "[124]\teval-merror:0.52838\ttrain-merror:0.50138\n",
      "[125]\teval-merror:0.52838\ttrain-merror:0.50126\n",
      "[126]\teval-merror:0.52632\ttrain-merror:0.50034\n",
      "[127]\teval-merror:0.52735\ttrain-merror:0.50057\n",
      "[128]\teval-merror:0.52735\ttrain-merror:0.50069\n",
      "[129]\teval-merror:0.52632\ttrain-merror:0.49989\n",
      "[130]\teval-merror:0.52941\ttrain-merror:0.49943\n",
      "[131]\teval-merror:0.53044\ttrain-merror:0.49920\n",
      "[132]\teval-merror:0.52528\ttrain-merror:0.49954\n",
      "[133]\teval-merror:0.52425\ttrain-merror:0.49966\n",
      "[134]\teval-merror:0.52632\ttrain-merror:0.49897\n",
      "[135]\teval-merror:0.52322\ttrain-merror:0.49931\n",
      "[136]\teval-merror:0.52528\ttrain-merror:0.49816\n",
      "[137]\teval-merror:0.52632\ttrain-merror:0.49805\n",
      "[138]\teval-merror:0.52425\ttrain-merror:0.49805\n",
      "[139]\teval-merror:0.52425\ttrain-merror:0.49782\n",
      "[140]\teval-merror:0.52425\ttrain-merror:0.49805\n",
      "[141]\teval-merror:0.52425\ttrain-merror:0.49782\n",
      "[142]\teval-merror:0.52012\ttrain-merror:0.49724\n",
      "[143]\teval-merror:0.52219\ttrain-merror:0.49724\n",
      "[144]\teval-merror:0.52012\ttrain-merror:0.49667\n",
      "[145]\teval-merror:0.52116\ttrain-merror:0.49690\n",
      "[146]\teval-merror:0.52012\ttrain-merror:0.49679\n",
      "[147]\teval-merror:0.52012\ttrain-merror:0.49702\n",
      "[148]\teval-merror:0.52116\ttrain-merror:0.49598\n",
      "[149]\teval-merror:0.52322\ttrain-merror:0.49621\n",
      "[150]\teval-merror:0.52322\ttrain-merror:0.49633\n",
      "[151]\teval-merror:0.52116\ttrain-merror:0.49633\n",
      "[152]\teval-merror:0.52116\ttrain-merror:0.49656\n",
      "[153]\teval-merror:0.52116\ttrain-merror:0.49610\n",
      "[154]\teval-merror:0.52116\ttrain-merror:0.49656\n",
      "[155]\teval-merror:0.52012\ttrain-merror:0.49667\n",
      "[156]\teval-merror:0.52219\ttrain-merror:0.49667\n",
      "[157]\teval-merror:0.52322\ttrain-merror:0.49667\n",
      "[158]\teval-merror:0.52219\ttrain-merror:0.49679\n",
      "[159]\teval-merror:0.52322\ttrain-merror:0.49621\n",
      "[160]\teval-merror:0.52219\ttrain-merror:0.49598\n",
      "[161]\teval-merror:0.52219\ttrain-merror:0.49621\n",
      "[162]\teval-merror:0.52116\ttrain-merror:0.49598\n",
      "[163]\teval-merror:0.52219\ttrain-merror:0.49621\n",
      "[164]\teval-merror:0.52116\ttrain-merror:0.49587\n",
      "[165]\teval-merror:0.51806\ttrain-merror:0.49392\n",
      "[166]\teval-merror:0.51703\ttrain-merror:0.49334\n",
      "[167]\teval-merror:0.51909\ttrain-merror:0.49484\n",
      "[168]\teval-merror:0.51703\ttrain-merror:0.49311\n",
      "[169]\teval-merror:0.51600\ttrain-merror:0.49369\n",
      "[170]\teval-merror:0.51806\ttrain-merror:0.49392\n",
      "[171]\teval-merror:0.51909\ttrain-merror:0.49415\n",
      "[172]\teval-merror:0.51909\ttrain-merror:0.49369\n",
      "[173]\teval-merror:0.51909\ttrain-merror:0.49334\n",
      "[174]\teval-merror:0.51909\ttrain-merror:0.49380\n",
      "[175]\teval-merror:0.51909\ttrain-merror:0.49346\n",
      "[176]\teval-merror:0.51909\ttrain-merror:0.49311\n",
      "[177]\teval-merror:0.51909\ttrain-merror:0.49300\n",
      "[178]\teval-merror:0.51909\ttrain-merror:0.49288\n",
      "[179]\teval-merror:0.51909\ttrain-merror:0.49346\n",
      "[180]\teval-merror:0.52012\ttrain-merror:0.49277\n",
      "[181]\teval-merror:0.51909\ttrain-merror:0.49277\n",
      "[182]\teval-merror:0.51806\ttrain-merror:0.49265\n",
      "[183]\teval-merror:0.51909\ttrain-merror:0.49265\n",
      "[184]\teval-merror:0.51703\ttrain-merror:0.49208\n",
      "[185]\teval-merror:0.51703\ttrain-merror:0.49265\n",
      "[186]\teval-merror:0.51806\ttrain-merror:0.49185\n",
      "[187]\teval-merror:0.51806\ttrain-merror:0.49265\n",
      "[188]\teval-merror:0.51806\ttrain-merror:0.49185\n",
      "[189]\teval-merror:0.51703\ttrain-merror:0.49196\n",
      "[190]\teval-merror:0.51909\ttrain-merror:0.49219\n",
      "[191]\teval-merror:0.51909\ttrain-merror:0.49208\n",
      "[192]\teval-merror:0.51909\ttrain-merror:0.49219\n",
      "[193]\teval-merror:0.51909\ttrain-merror:0.49128\n",
      "[194]\teval-merror:0.51703\ttrain-merror:0.49162\n",
      "[195]\teval-merror:0.51703\ttrain-merror:0.49151\n",
      "[196]\teval-merror:0.51600\ttrain-merror:0.49208\n",
      "[197]\teval-merror:0.51806\ttrain-merror:0.49208\n",
      "[198]\teval-merror:0.51806\ttrain-merror:0.49196\n",
      "[199]\teval-merror:0.51806\ttrain-merror:0.49196\n",
      "[200]\teval-merror:0.51703\ttrain-merror:0.49139\n",
      "[201]\teval-merror:0.51806\ttrain-merror:0.49151\n",
      "[202]\teval-merror:0.51703\ttrain-merror:0.49116\n",
      "[203]\teval-merror:0.51909\ttrain-merror:0.49174\n",
      "[204]\teval-merror:0.51600\ttrain-merror:0.49105\n",
      "[205]\teval-merror:0.51600\ttrain-merror:0.49047\n",
      "[206]\teval-merror:0.51600\ttrain-merror:0.49047\n",
      "[207]\teval-merror:0.51600\ttrain-merror:0.49047\n",
      "[208]\teval-merror:0.51703\ttrain-merror:0.49059\n",
      "[209]\teval-merror:0.51703\ttrain-merror:0.48933\n",
      "[210]\teval-merror:0.51703\ttrain-merror:0.48944\n",
      "[211]\teval-merror:0.51393\ttrain-merror:0.48944\n",
      "[212]\teval-merror:0.51393\ttrain-merror:0.48933\n",
      "[213]\teval-merror:0.51496\ttrain-merror:0.48806\n",
      "[214]\teval-merror:0.51496\ttrain-merror:0.48841\n",
      "[215]\teval-merror:0.51496\ttrain-merror:0.48818\n",
      "[216]\teval-merror:0.51600\ttrain-merror:0.48956\n",
      "[217]\teval-merror:0.51393\ttrain-merror:0.48875\n",
      "[218]\teval-merror:0.51393\ttrain-merror:0.48910\n",
      "[219]\teval-merror:0.51393\ttrain-merror:0.48898\n",
      "[220]\teval-merror:0.51290\ttrain-merror:0.48910\n",
      "[221]\teval-merror:0.51393\ttrain-merror:0.48841\n",
      "[222]\teval-merror:0.51290\ttrain-merror:0.48887\n",
      "[223]\teval-merror:0.51187\ttrain-merror:0.48829\n",
      "[224]\teval-merror:0.51187\ttrain-merror:0.48841\n",
      "[225]\teval-merror:0.51084\ttrain-merror:0.48887\n",
      "[226]\teval-merror:0.51084\ttrain-merror:0.48910\n",
      "[227]\teval-merror:0.51290\ttrain-merror:0.48864\n",
      "[228]\teval-merror:0.51290\ttrain-merror:0.48864\n",
      "[229]\teval-merror:0.51084\ttrain-merror:0.48829\n",
      "[230]\teval-merror:0.51187\ttrain-merror:0.48841\n",
      "[231]\teval-merror:0.51187\ttrain-merror:0.48829\n",
      "[232]\teval-merror:0.51290\ttrain-merror:0.48806\n",
      "[233]\teval-merror:0.51290\ttrain-merror:0.48829\n",
      "[234]\teval-merror:0.51187\ttrain-merror:0.48806\n",
      "[235]\teval-merror:0.51187\ttrain-merror:0.48737\n",
      "[236]\teval-merror:0.51496\ttrain-merror:0.48760\n",
      "[237]\teval-merror:0.51393\ttrain-merror:0.48737\n",
      "[238]\teval-merror:0.51393\ttrain-merror:0.48749\n",
      "[239]\teval-merror:0.51393\ttrain-merror:0.48726\n",
      "[240]\teval-merror:0.51393\ttrain-merror:0.48818\n",
      "[241]\teval-merror:0.51187\ttrain-merror:0.48714\n",
      "[242]\teval-merror:0.51187\ttrain-merror:0.48668\n",
      "[243]\teval-merror:0.51393\ttrain-merror:0.48680\n",
      "[244]\teval-merror:0.51290\ttrain-merror:0.48668\n",
      "[245]\teval-merror:0.51187\ttrain-merror:0.48691\n",
      "[246]\teval-merror:0.51290\ttrain-merror:0.48691\n",
      "[247]\teval-merror:0.51393\ttrain-merror:0.48588\n",
      "[248]\teval-merror:0.51600\ttrain-merror:0.48623\n",
      "[249]\teval-merror:0.51600\ttrain-merror:0.48600\n",
      "[250]\teval-merror:0.51496\ttrain-merror:0.48542\n",
      "[251]\teval-merror:0.51393\ttrain-merror:0.48508\n",
      "[252]\teval-merror:0.51290\ttrain-merror:0.48531\n",
      "[253]\teval-merror:0.51393\ttrain-merror:0.48542\n",
      "[254]\teval-merror:0.51393\ttrain-merror:0.48519\n",
      "[255]\teval-merror:0.51393\ttrain-merror:0.48542\n",
      "[256]\teval-merror:0.51393\ttrain-merror:0.48473\n",
      "[257]\teval-merror:0.51290\ttrain-merror:0.48485\n",
      "[258]\teval-merror:0.51393\ttrain-merror:0.48496\n",
      "[259]\teval-merror:0.51393\ttrain-merror:0.48462\n",
      "[260]\teval-merror:0.51187\ttrain-merror:0.48462\n",
      "[261]\teval-merror:0.51187\ttrain-merror:0.48450\n",
      "[262]\teval-merror:0.51187\ttrain-merror:0.48381\n",
      "[263]\teval-merror:0.51290\ttrain-merror:0.48450\n",
      "[264]\teval-merror:0.51290\ttrain-merror:0.48473\n",
      "[265]\teval-merror:0.51290\ttrain-merror:0.48416\n",
      "[266]\teval-merror:0.51393\ttrain-merror:0.48416\n",
      "[267]\teval-merror:0.51290\ttrain-merror:0.48381\n",
      "[268]\teval-merror:0.51187\ttrain-merror:0.48405\n",
      "[269]\teval-merror:0.51187\ttrain-merror:0.48405\n",
      "[270]\teval-merror:0.51187\ttrain-merror:0.48393\n",
      "[271]\teval-merror:0.51187\ttrain-merror:0.48359\n",
      "[272]\teval-merror:0.50980\ttrain-merror:0.48393\n",
      "[273]\teval-merror:0.51084\ttrain-merror:0.48347\n",
      "[274]\teval-merror:0.51084\ttrain-merror:0.48359\n",
      "[275]\teval-merror:0.51084\ttrain-merror:0.48405\n",
      "[276]\teval-merror:0.51187\ttrain-merror:0.48381\n",
      "[277]\teval-merror:0.51084\ttrain-merror:0.48381\n",
      "[278]\teval-merror:0.51187\ttrain-merror:0.48359\n",
      "[279]\teval-merror:0.51084\ttrain-merror:0.48278\n",
      "[280]\teval-merror:0.51187\ttrain-merror:0.48336\n",
      "[281]\teval-merror:0.50980\ttrain-merror:0.48347\n",
      "[282]\teval-merror:0.50980\ttrain-merror:0.48313\n",
      "[283]\teval-merror:0.50980\ttrain-merror:0.48313\n",
      "[284]\teval-merror:0.50980\ttrain-merror:0.48290\n",
      "[285]\teval-merror:0.50980\ttrain-merror:0.48278\n",
      "[286]\teval-merror:0.50980\ttrain-merror:0.48255\n",
      "[287]\teval-merror:0.51187\ttrain-merror:0.48313\n",
      "[288]\teval-merror:0.50980\ttrain-merror:0.48290\n",
      "[289]\teval-merror:0.51084\ttrain-merror:0.48244\n",
      "[290]\teval-merror:0.51084\ttrain-merror:0.48267\n",
      "[291]\teval-merror:0.50980\ttrain-merror:0.48290\n",
      "[292]\teval-merror:0.51084\ttrain-merror:0.48313\n",
      "[293]\teval-merror:0.51084\ttrain-merror:0.48267\n",
      "[294]\teval-merror:0.51084\ttrain-merror:0.48163\n",
      "[295]\teval-merror:0.51084\ttrain-merror:0.48244\n",
      "[296]\teval-merror:0.51084\ttrain-merror:0.48198\n",
      "[297]\teval-merror:0.51084\ttrain-merror:0.48255\n",
      "[298]\teval-merror:0.51084\ttrain-merror:0.48255\n",
      "[299]\teval-merror:0.51084\ttrain-merror:0.48198\n",
      "[300]\teval-merror:0.51084\ttrain-merror:0.48186\n",
      "[301]\teval-merror:0.51084\ttrain-merror:0.48221\n",
      "[302]\teval-merror:0.51084\ttrain-merror:0.48267\n",
      "[303]\teval-merror:0.51084\ttrain-merror:0.48255\n",
      "[304]\teval-merror:0.51084\ttrain-merror:0.48232\n",
      "[305]\teval-merror:0.51187\ttrain-merror:0.48232\n",
      "[306]\teval-merror:0.50980\ttrain-merror:0.48301\n",
      "[307]\teval-merror:0.50980\ttrain-merror:0.48232\n",
      "[308]\teval-merror:0.51084\ttrain-merror:0.48232\n",
      "[309]\teval-merror:0.51084\ttrain-merror:0.48152\n",
      "[310]\teval-merror:0.51084\ttrain-merror:0.48186\n",
      "[311]\teval-merror:0.51084\ttrain-merror:0.48221\n",
      "[312]\teval-merror:0.51084\ttrain-merror:0.48278\n",
      "[313]\teval-merror:0.51084\ttrain-merror:0.48278\n",
      "[314]\teval-merror:0.51084\ttrain-merror:0.48255\n",
      "[315]\teval-merror:0.51084\ttrain-merror:0.48232\n",
      "[316]\teval-merror:0.50980\ttrain-merror:0.48267\n",
      "[317]\teval-merror:0.50980\ttrain-merror:0.48221\n",
      "[318]\teval-merror:0.51084\ttrain-merror:0.48232\n",
      "[319]\teval-merror:0.51084\ttrain-merror:0.48359\n",
      "[320]\teval-merror:0.51187\ttrain-merror:0.48290\n",
      "[321]\teval-merror:0.51084\ttrain-merror:0.48278\n",
      "[322]\teval-merror:0.51084\ttrain-merror:0.48278\n",
      "[323]\teval-merror:0.51187\ttrain-merror:0.48244\n",
      "[324]\teval-merror:0.51084\ttrain-merror:0.48267\n",
      "[325]\teval-merror:0.51084\ttrain-merror:0.48186\n",
      "[326]\teval-merror:0.50877\ttrain-merror:0.48198\n",
      "[327]\teval-merror:0.50980\ttrain-merror:0.48163\n",
      "[328]\teval-merror:0.51187\ttrain-merror:0.48106\n",
      "[329]\teval-merror:0.51084\ttrain-merror:0.48152\n",
      "[330]\teval-merror:0.51084\ttrain-merror:0.48072\n",
      "[331]\teval-merror:0.50980\ttrain-merror:0.48118\n",
      "[332]\teval-merror:0.51084\ttrain-merror:0.48118\n",
      "[333]\teval-merror:0.51084\ttrain-merror:0.48141\n",
      "[334]\teval-merror:0.50877\ttrain-merror:0.48118\n",
      "[335]\teval-merror:0.50980\ttrain-merror:0.48118\n",
      "[336]\teval-merror:0.50877\ttrain-merror:0.48129\n",
      "[337]\teval-merror:0.50774\ttrain-merror:0.48152\n",
      "[338]\teval-merror:0.50774\ttrain-merror:0.48232\n",
      "[339]\teval-merror:0.50774\ttrain-merror:0.48152\n",
      "[340]\teval-merror:0.50671\ttrain-merror:0.48175\n",
      "[341]\teval-merror:0.50774\ttrain-merror:0.48141\n",
      "[342]\teval-merror:0.50980\ttrain-merror:0.48118\n",
      "[343]\teval-merror:0.50877\ttrain-merror:0.48118\n",
      "[344]\teval-merror:0.50877\ttrain-merror:0.48198\n",
      "[345]\teval-merror:0.50877\ttrain-merror:0.48152\n",
      "[346]\teval-merror:0.50774\ttrain-merror:0.48175\n",
      "[347]\teval-merror:0.50877\ttrain-merror:0.48209\n",
      "[348]\teval-merror:0.50877\ttrain-merror:0.48129\n",
      "[349]\teval-merror:0.50980\ttrain-merror:0.48141\n",
      "[350]\teval-merror:0.51084\ttrain-merror:0.48129\n",
      "[351]\teval-merror:0.51084\ttrain-merror:0.48129\n",
      "[352]\teval-merror:0.50877\ttrain-merror:0.48152\n",
      "[353]\teval-merror:0.50877\ttrain-merror:0.48083\n",
      "[354]\teval-merror:0.50980\ttrain-merror:0.48106\n",
      "[355]\teval-merror:0.51187\ttrain-merror:0.48106\n",
      "[356]\teval-merror:0.51187\ttrain-merror:0.48152\n",
      "[357]\teval-merror:0.51084\ttrain-merror:0.48095\n",
      "[358]\teval-merror:0.50774\ttrain-merror:0.48129\n",
      "[359]\teval-merror:0.50877\ttrain-merror:0.48118\n",
      "[360]\teval-merror:0.50671\ttrain-merror:0.48106\n",
      "[361]\teval-merror:0.50774\ttrain-merror:0.48129\n",
      "[362]\teval-merror:0.50980\ttrain-merror:0.48118\n",
      "[363]\teval-merror:0.50980\ttrain-merror:0.48106\n",
      "[364]\teval-merror:0.50464\ttrain-merror:0.48163\n",
      "[365]\teval-merror:0.50361\ttrain-merror:0.48175\n",
      "[366]\teval-merror:0.50568\ttrain-merror:0.48152\n",
      "[367]\teval-merror:0.50464\ttrain-merror:0.48175\n",
      "[368]\teval-merror:0.50568\ttrain-merror:0.48129\n",
      "[369]\teval-merror:0.50568\ttrain-merror:0.48175\n",
      "[370]\teval-merror:0.50671\ttrain-merror:0.48152\n",
      "[371]\teval-merror:0.50671\ttrain-merror:0.48129\n",
      "[372]\teval-merror:0.50671\ttrain-merror:0.48152\n",
      "[373]\teval-merror:0.50464\ttrain-merror:0.48163\n",
      "[374]\teval-merror:0.50568\ttrain-merror:0.48152\n",
      "[375]\teval-merror:0.50568\ttrain-merror:0.48118\n",
      "[376]\teval-merror:0.50464\ttrain-merror:0.48141\n",
      "[377]\teval-merror:0.50568\ttrain-merror:0.48163\n",
      "[378]\teval-merror:0.50671\ttrain-merror:0.48163\n",
      "[379]\teval-merror:0.50568\ttrain-merror:0.48141\n",
      "[380]\teval-merror:0.50568\ttrain-merror:0.48163\n",
      "[381]\teval-merror:0.50568\ttrain-merror:0.48129\n",
      "[382]\teval-merror:0.50568\ttrain-merror:0.48118\n",
      "[383]\teval-merror:0.50568\ttrain-merror:0.48163\n",
      "[384]\teval-merror:0.50464\ttrain-merror:0.48152\n",
      "[385]\teval-merror:0.50568\ttrain-merror:0.48152\n",
      "[386]\teval-merror:0.50464\ttrain-merror:0.48129\n",
      "[387]\teval-merror:0.50568\ttrain-merror:0.48129\n",
      "[388]\teval-merror:0.50568\ttrain-merror:0.48141\n",
      "[389]\teval-merror:0.50464\ttrain-merror:0.48129\n",
      "[390]\teval-merror:0.50361\ttrain-merror:0.48129\n",
      "[391]\teval-merror:0.50361\ttrain-merror:0.48152\n",
      "[392]\teval-merror:0.50464\ttrain-merror:0.48175\n",
      "[393]\teval-merror:0.50464\ttrain-merror:0.48141\n",
      "[394]\teval-merror:0.50464\ttrain-merror:0.48141\n",
      "[395]\teval-merror:0.50464\ttrain-merror:0.48118\n",
      "[396]\teval-merror:0.50361\ttrain-merror:0.48129\n",
      "[397]\teval-merror:0.50568\ttrain-merror:0.48152\n",
      "[398]\teval-merror:0.50774\ttrain-merror:0.48129\n",
      "[399]\teval-merror:0.50671\ttrain-merror:0.48141\n",
      "[400]\teval-merror:0.50671\ttrain-merror:0.48163\n",
      "[401]\teval-merror:0.50671\ttrain-merror:0.48152\n",
      "[402]\teval-merror:0.50671\ttrain-merror:0.48141\n",
      "[403]\teval-merror:0.50671\ttrain-merror:0.48141\n",
      "[404]\teval-merror:0.50568\ttrain-merror:0.48129\n",
      "[405]\teval-merror:0.50568\ttrain-merror:0.48118\n",
      "[406]\teval-merror:0.50568\ttrain-merror:0.48083\n",
      "[407]\teval-merror:0.50568\ttrain-merror:0.48118\n",
      "[408]\teval-merror:0.50361\ttrain-merror:0.48095\n",
      "[409]\teval-merror:0.50361\ttrain-merror:0.48106\n",
      "[410]\teval-merror:0.50361\ttrain-merror:0.48095\n",
      "[411]\teval-merror:0.50361\ttrain-merror:0.48106\n",
      "[412]\teval-merror:0.50361\ttrain-merror:0.48095\n",
      "[413]\teval-merror:0.50258\ttrain-merror:0.48106\n",
      "[414]\teval-merror:0.50258\ttrain-merror:0.48106\n",
      "[415]\teval-merror:0.50258\ttrain-merror:0.48106\n",
      "[416]\teval-merror:0.50258\ttrain-merror:0.48106\n",
      "[417]\teval-merror:0.50361\ttrain-merror:0.48106\n",
      "[418]\teval-merror:0.50464\ttrain-merror:0.48106\n",
      "[419]\teval-merror:0.50361\ttrain-merror:0.48106\n",
      "[420]\teval-merror:0.50464\ttrain-merror:0.48072\n",
      "[421]\teval-merror:0.50258\ttrain-merror:0.48083\n",
      "[422]\teval-merror:0.50361\ttrain-merror:0.48060\n",
      "[423]\teval-merror:0.50361\ttrain-merror:0.48049\n",
      "[424]\teval-merror:0.50258\ttrain-merror:0.48049\n",
      "[425]\teval-merror:0.50361\ttrain-merror:0.48060\n",
      "[426]\teval-merror:0.50258\ttrain-merror:0.48003\n",
      "[427]\teval-merror:0.50361\ttrain-merror:0.48014\n",
      "[428]\teval-merror:0.50361\ttrain-merror:0.48072\n",
      "[429]\teval-merror:0.50361\ttrain-merror:0.48095\n",
      "[430]\teval-merror:0.50258\ttrain-merror:0.48095\n",
      "[431]\teval-merror:0.50464\ttrain-merror:0.48152\n",
      "[432]\teval-merror:0.50464\ttrain-merror:0.48141\n",
      "[433]\teval-merror:0.50464\ttrain-merror:0.48129\n",
      "[434]\teval-merror:0.50464\ttrain-merror:0.48072\n",
      "[435]\teval-merror:0.50464\ttrain-merror:0.48026\n",
      "[436]\teval-merror:0.50361\ttrain-merror:0.48060\n",
      "[437]\teval-merror:0.50361\ttrain-merror:0.48037\n",
      "[438]\teval-merror:0.50155\ttrain-merror:0.48014\n",
      "[439]\teval-merror:0.50155\ttrain-merror:0.48026\n",
      "[440]\teval-merror:0.50155\ttrain-merror:0.48072\n",
      "[441]\teval-merror:0.50052\ttrain-merror:0.48049\n",
      "[442]\teval-merror:0.49948\ttrain-merror:0.47980\n",
      "[443]\teval-merror:0.50155\ttrain-merror:0.48003\n",
      "[444]\teval-merror:0.50258\ttrain-merror:0.48003\n",
      "[445]\teval-merror:0.50258\ttrain-merror:0.47980\n",
      "[446]\teval-merror:0.50464\ttrain-merror:0.47980\n",
      "[447]\teval-merror:0.50464\ttrain-merror:0.47957\n",
      "[448]\teval-merror:0.50568\ttrain-merror:0.48014\n",
      "[449]\teval-merror:0.50464\ttrain-merror:0.48014\n",
      "[450]\teval-merror:0.50361\ttrain-merror:0.48072\n",
      "[451]\teval-merror:0.50361\ttrain-merror:0.48037\n",
      "[452]\teval-merror:0.50258\ttrain-merror:0.48014\n",
      "[453]\teval-merror:0.50155\ttrain-merror:0.48014\n",
      "[454]\teval-merror:0.50155\ttrain-merror:0.47957\n",
      "[455]\teval-merror:0.50258\ttrain-merror:0.47991\n",
      "[456]\teval-merror:0.50258\ttrain-merror:0.48037\n",
      "[457]\teval-merror:0.50258\ttrain-merror:0.48014\n",
      "[458]\teval-merror:0.50361\ttrain-merror:0.48014\n",
      "[459]\teval-merror:0.50361\ttrain-merror:0.47980\n",
      "[460]\teval-merror:0.50155\ttrain-merror:0.47934\n",
      "[461]\teval-merror:0.50258\ttrain-merror:0.47945\n",
      "[462]\teval-merror:0.50155\ttrain-merror:0.47957\n",
      "[463]\teval-merror:0.50155\ttrain-merror:0.47911\n",
      "[464]\teval-merror:0.50155\ttrain-merror:0.47945\n",
      "[465]\teval-merror:0.50258\ttrain-merror:0.47922\n",
      "[466]\teval-merror:0.50361\ttrain-merror:0.47968\n",
      "[467]\teval-merror:0.50464\ttrain-merror:0.47968\n",
      "[468]\teval-merror:0.50361\ttrain-merror:0.47957\n",
      "[469]\teval-merror:0.50464\ttrain-merror:0.47968\n",
      "[470]\teval-merror:0.50464\ttrain-merror:0.47934\n",
      "[471]\teval-merror:0.50361\ttrain-merror:0.47911\n",
      "[472]\teval-merror:0.50361\ttrain-merror:0.47911\n",
      "[473]\teval-merror:0.50361\ttrain-merror:0.47934\n",
      "[474]\teval-merror:0.50258\ttrain-merror:0.47957\n",
      "[475]\teval-merror:0.50258\ttrain-merror:0.47945\n",
      "[476]\teval-merror:0.50052\ttrain-merror:0.47911\n",
      "[477]\teval-merror:0.50052\ttrain-merror:0.47922\n",
      "[478]\teval-merror:0.50052\ttrain-merror:0.47911\n",
      "[479]\teval-merror:0.50052\ttrain-merror:0.47876\n",
      "[480]\teval-merror:0.50052\ttrain-merror:0.47876\n",
      "[481]\teval-merror:0.50052\ttrain-merror:0.47853\n",
      "[482]\teval-merror:0.50052\ttrain-merror:0.47853\n",
      "[483]\teval-merror:0.50052\ttrain-merror:0.47911\n",
      "[484]\teval-merror:0.50052\ttrain-merror:0.47853\n",
      "[485]\teval-merror:0.50052\ttrain-merror:0.47911\n",
      "[486]\teval-merror:0.50155\ttrain-merror:0.47911\n",
      "[487]\teval-merror:0.50258\ttrain-merror:0.47876\n",
      "[488]\teval-merror:0.50155\ttrain-merror:0.47876\n",
      "[489]\teval-merror:0.50155\ttrain-merror:0.47865\n",
      "[490]\teval-merror:0.50155\ttrain-merror:0.47831\n",
      "[491]\teval-merror:0.50155\ttrain-merror:0.47831\n",
      "[492]\teval-merror:0.50155\ttrain-merror:0.47888\n",
      "[493]\teval-merror:0.50155\ttrain-merror:0.47888\n",
      "[494]\teval-merror:0.50155\ttrain-merror:0.47865\n",
      "[495]\teval-merror:0.50258\ttrain-merror:0.47853\n",
      "[496]\teval-merror:0.50155\ttrain-merror:0.47842\n",
      "[497]\teval-merror:0.50258\ttrain-merror:0.47876\n",
      "[498]\teval-merror:0.50258\ttrain-merror:0.47865\n",
      "[499]\teval-merror:0.50155\ttrain-merror:0.47842\n",
      "2\n",
      "[0]\teval-merror:0.58471\ttrain-merror:0.56490\n",
      "[1]\teval-merror:0.58471\ttrain-merror:0.56490\n",
      "[2]\teval-merror:0.58471\ttrain-merror:0.56490\n",
      "[3]\teval-merror:0.58471\ttrain-merror:0.56490\n",
      "[4]\teval-merror:0.55165\ttrain-merror:0.54528\n",
      "[5]\teval-merror:0.55165\ttrain-merror:0.54528\n",
      "[6]\teval-merror:0.55165\ttrain-merror:0.54528\n",
      "[7]\teval-merror:0.55165\ttrain-merror:0.54493\n",
      "[8]\teval-merror:0.54855\ttrain-merror:0.54574\n",
      "[9]\teval-merror:0.54855\ttrain-merror:0.54574\n",
      "[10]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[11]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[12]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[13]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[14]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[15]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[16]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[17]\teval-merror:0.55062\ttrain-merror:0.54597\n",
      "[18]\teval-merror:0.52376\ttrain-merror:0.53139\n",
      "[19]\teval-merror:0.54855\ttrain-merror:0.54562\n",
      "[20]\teval-merror:0.52376\ttrain-merror:0.53139\n",
      "[21]\teval-merror:0.52376\ttrain-merror:0.53151\n",
      "[22]\teval-merror:0.52376\ttrain-merror:0.53151\n",
      "[23]\teval-merror:0.52376\ttrain-merror:0.53151\n",
      "[24]\teval-merror:0.52376\ttrain-merror:0.53128\n",
      "[25]\teval-merror:0.52376\ttrain-merror:0.53151\n",
      "[26]\teval-merror:0.52376\ttrain-merror:0.53139\n",
      "[27]\teval-merror:0.51240\ttrain-merror:0.52313\n",
      "[28]\teval-merror:0.51240\ttrain-merror:0.52324\n",
      "[29]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[30]\teval-merror:0.51240\ttrain-merror:0.52313\n",
      "[31]\teval-merror:0.51240\ttrain-merror:0.52313\n",
      "[32]\teval-merror:0.51240\ttrain-merror:0.52313\n",
      "[33]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[34]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[35]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[36]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[37]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[38]\teval-merror:0.50930\ttrain-merror:0.52221\n",
      "[39]\teval-merror:0.50930\ttrain-merror:0.52232\n",
      "[40]\teval-merror:0.51033\ttrain-merror:0.52232\n",
      "[41]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[42]\teval-merror:0.51033\ttrain-merror:0.52232\n",
      "[43]\teval-merror:0.51033\ttrain-merror:0.52232\n",
      "[44]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[45]\teval-merror:0.51033\ttrain-merror:0.52255\n",
      "[46]\teval-merror:0.51033\ttrain-merror:0.52255\n",
      "[47]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[48]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[49]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[50]\teval-merror:0.51033\ttrain-merror:0.52255\n",
      "[51]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[52]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[53]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[54]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[55]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[56]\teval-merror:0.50826\ttrain-merror:0.52244\n",
      "[57]\teval-merror:0.51033\ttrain-merror:0.52244\n",
      "[58]\teval-merror:0.50826\ttrain-merror:0.52244\n",
      "[59]\teval-merror:0.50826\ttrain-merror:0.52244\n",
      "[60]\teval-merror:0.50930\ttrain-merror:0.52244\n",
      "[61]\teval-merror:0.50620\ttrain-merror:0.52106\n",
      "[62]\teval-merror:0.50516\ttrain-merror:0.51314\n",
      "[63]\teval-merror:0.50516\ttrain-merror:0.51314\n",
      "[64]\teval-merror:0.50516\ttrain-merror:0.51326\n",
      "[65]\teval-merror:0.50413\ttrain-merror:0.51326\n",
      "[66]\teval-merror:0.50516\ttrain-merror:0.51326\n",
      "[67]\teval-merror:0.50516\ttrain-merror:0.51326\n",
      "[68]\teval-merror:0.50516\ttrain-merror:0.51360\n",
      "[69]\teval-merror:0.50516\ttrain-merror:0.51326\n",
      "[70]\teval-merror:0.50516\ttrain-merror:0.51337\n",
      "[71]\teval-merror:0.50310\ttrain-merror:0.51188\n",
      "[72]\teval-merror:0.50413\ttrain-merror:0.51176\n",
      "[73]\teval-merror:0.50207\ttrain-merror:0.51245\n",
      "[74]\teval-merror:0.50000\ttrain-merror:0.51085\n",
      "[75]\teval-merror:0.50103\ttrain-merror:0.51039\n",
      "[76]\teval-merror:0.50103\ttrain-merror:0.51107\n",
      "[77]\teval-merror:0.50310\ttrain-merror:0.50729\n",
      "[78]\teval-merror:0.50103\ttrain-merror:0.51119\n",
      "[79]\teval-merror:0.50207\ttrain-merror:0.50614\n",
      "[80]\teval-merror:0.50103\ttrain-merror:0.50637\n",
      "[81]\teval-merror:0.49690\ttrain-merror:0.50557\n",
      "[82]\teval-merror:0.49897\ttrain-merror:0.50557\n",
      "[83]\teval-merror:0.49897\ttrain-merror:0.50568\n",
      "[84]\teval-merror:0.49277\ttrain-merror:0.50362\n",
      "[85]\teval-merror:0.49070\ttrain-merror:0.50304\n",
      "[86]\teval-merror:0.48967\ttrain-merror:0.50293\n",
      "[87]\teval-merror:0.49070\ttrain-merror:0.50270\n",
      "[88]\teval-merror:0.48967\ttrain-merror:0.50224\n",
      "[89]\teval-merror:0.49174\ttrain-merror:0.50247\n",
      "[90]\teval-merror:0.48967\ttrain-merror:0.50201\n",
      "[91]\teval-merror:0.49174\ttrain-merror:0.50155\n",
      "[92]\teval-merror:0.48554\ttrain-merror:0.50109\n",
      "[93]\teval-merror:0.48657\ttrain-merror:0.50052\n",
      "[94]\teval-merror:0.48554\ttrain-merror:0.50109\n",
      "[95]\teval-merror:0.48554\ttrain-merror:0.50121\n",
      "[96]\teval-merror:0.48760\ttrain-merror:0.50040\n",
      "[97]\teval-merror:0.48864\ttrain-merror:0.50086\n",
      "[98]\teval-merror:0.48864\ttrain-merror:0.50086\n",
      "[99]\teval-merror:0.48760\ttrain-merror:0.50075\n",
      "[100]\teval-merror:0.48864\ttrain-merror:0.50075\n",
      "[101]\teval-merror:0.48760\ttrain-merror:0.50063\n",
      "[102]\teval-merror:0.48760\ttrain-merror:0.50155\n",
      "[103]\teval-merror:0.48760\ttrain-merror:0.50109\n",
      "[104]\teval-merror:0.48967\ttrain-merror:0.50075\n",
      "[105]\teval-merror:0.48657\ttrain-merror:0.50063\n",
      "[106]\teval-merror:0.48450\ttrain-merror:0.50040\n",
      "[107]\teval-merror:0.48760\ttrain-merror:0.49971\n",
      "[108]\teval-merror:0.48554\ttrain-merror:0.50006\n",
      "[109]\teval-merror:0.48450\ttrain-merror:0.50017\n",
      "[110]\teval-merror:0.48244\ttrain-merror:0.50017\n",
      "[111]\teval-merror:0.48141\ttrain-merror:0.50017\n",
      "[112]\teval-merror:0.47934\ttrain-merror:0.49948\n",
      "[113]\teval-merror:0.47934\ttrain-merror:0.50006\n",
      "[114]\teval-merror:0.47727\ttrain-merror:0.49914\n",
      "[115]\teval-merror:0.47831\ttrain-merror:0.49960\n",
      "[116]\teval-merror:0.47727\ttrain-merror:0.49937\n",
      "[117]\teval-merror:0.48037\ttrain-merror:0.49983\n",
      "[118]\teval-merror:0.47831\ttrain-merror:0.49811\n",
      "[119]\teval-merror:0.47831\ttrain-merror:0.49776\n",
      "[120]\teval-merror:0.47831\ttrain-merror:0.49765\n",
      "[121]\teval-merror:0.47934\ttrain-merror:0.49696\n",
      "[122]\teval-merror:0.48037\ttrain-merror:0.49742\n",
      "[123]\teval-merror:0.47934\ttrain-merror:0.49684\n",
      "[124]\teval-merror:0.47934\ttrain-merror:0.49753\n",
      "[125]\teval-merror:0.47934\ttrain-merror:0.49639\n",
      "[126]\teval-merror:0.47934\ttrain-merror:0.49696\n",
      "[127]\teval-merror:0.47934\ttrain-merror:0.49650\n",
      "[128]\teval-merror:0.48244\ttrain-merror:0.49719\n",
      "[129]\teval-merror:0.48347\ttrain-merror:0.49868\n",
      "[130]\teval-merror:0.48347\ttrain-merror:0.49684\n",
      "[131]\teval-merror:0.48244\ttrain-merror:0.49604\n",
      "[132]\teval-merror:0.48244\ttrain-merror:0.49650\n",
      "[133]\teval-merror:0.48141\ttrain-merror:0.49639\n",
      "[134]\teval-merror:0.48450\ttrain-merror:0.49581\n",
      "[135]\teval-merror:0.48347\ttrain-merror:0.49581\n",
      "[136]\teval-merror:0.48347\ttrain-merror:0.49627\n",
      "[137]\teval-merror:0.48347\ttrain-merror:0.49616\n",
      "[138]\teval-merror:0.48347\ttrain-merror:0.49661\n",
      "[139]\teval-merror:0.48244\ttrain-merror:0.49696\n",
      "[140]\teval-merror:0.48347\ttrain-merror:0.49661\n",
      "[141]\teval-merror:0.48347\ttrain-merror:0.49570\n",
      "[142]\teval-merror:0.48244\ttrain-merror:0.49570\n",
      "[143]\teval-merror:0.48244\ttrain-merror:0.49547\n",
      "[144]\teval-merror:0.48347\ttrain-merror:0.49558\n",
      "[145]\teval-merror:0.48347\ttrain-merror:0.49535\n",
      "[146]\teval-merror:0.48347\ttrain-merror:0.49524\n",
      "[147]\teval-merror:0.48347\ttrain-merror:0.49535\n",
      "[148]\teval-merror:0.48347\ttrain-merror:0.49547\n",
      "[149]\teval-merror:0.48450\ttrain-merror:0.49547\n",
      "[150]\teval-merror:0.48450\ttrain-merror:0.49524\n",
      "[151]\teval-merror:0.48450\ttrain-merror:0.49593\n",
      "[152]\teval-merror:0.48554\ttrain-merror:0.49581\n",
      "[153]\teval-merror:0.48657\ttrain-merror:0.49673\n",
      "[154]\teval-merror:0.48864\ttrain-merror:0.49570\n",
      "[155]\teval-merror:0.48657\ttrain-merror:0.49547\n",
      "[156]\teval-merror:0.48554\ttrain-merror:0.49478\n",
      "[157]\teval-merror:0.48450\ttrain-merror:0.49478\n",
      "[158]\teval-merror:0.48554\ttrain-merror:0.49455\n",
      "[159]\teval-merror:0.48554\ttrain-merror:0.49524\n",
      "[160]\teval-merror:0.48554\ttrain-merror:0.49547\n",
      "[161]\teval-merror:0.48554\ttrain-merror:0.49524\n",
      "[162]\teval-merror:0.48554\ttrain-merror:0.49489\n",
      "[163]\teval-merror:0.48657\ttrain-merror:0.49478\n",
      "[164]\teval-merror:0.48554\ttrain-merror:0.49535\n",
      "[165]\teval-merror:0.48554\ttrain-merror:0.49455\n",
      "[166]\teval-merror:0.48347\ttrain-merror:0.49237\n",
      "[167]\teval-merror:0.48244\ttrain-merror:0.49248\n",
      "[168]\teval-merror:0.48244\ttrain-merror:0.49191\n",
      "[169]\teval-merror:0.48244\ttrain-merror:0.49179\n",
      "[170]\teval-merror:0.48244\ttrain-merror:0.49134\n",
      "[171]\teval-merror:0.48244\ttrain-merror:0.49156\n",
      "[172]\teval-merror:0.48244\ttrain-merror:0.49145\n",
      "[173]\teval-merror:0.48450\ttrain-merror:0.49111\n",
      "[174]\teval-merror:0.48554\ttrain-merror:0.49248\n",
      "[175]\teval-merror:0.48244\ttrain-merror:0.49122\n",
      "[176]\teval-merror:0.48347\ttrain-merror:0.49214\n",
      "[177]\teval-merror:0.48450\ttrain-merror:0.49248\n",
      "[178]\teval-merror:0.48347\ttrain-merror:0.49260\n",
      "[179]\teval-merror:0.48554\ttrain-merror:0.49317\n",
      "[180]\teval-merror:0.48037\ttrain-merror:0.49122\n",
      "[181]\teval-merror:0.48347\ttrain-merror:0.49248\n",
      "[182]\teval-merror:0.47934\ttrain-merror:0.49168\n",
      "[183]\teval-merror:0.48037\ttrain-merror:0.49156\n",
      "[184]\teval-merror:0.48347\ttrain-merror:0.49214\n",
      "[185]\teval-merror:0.48141\ttrain-merror:0.49191\n",
      "[186]\teval-merror:0.48141\ttrain-merror:0.49179\n",
      "[187]\teval-merror:0.48244\ttrain-merror:0.49179\n",
      "[188]\teval-merror:0.48244\ttrain-merror:0.49237\n",
      "[189]\teval-merror:0.48244\ttrain-merror:0.49237\n",
      "[190]\teval-merror:0.48141\ttrain-merror:0.49214\n",
      "[191]\teval-merror:0.48141\ttrain-merror:0.49202\n",
      "[192]\teval-merror:0.48141\ttrain-merror:0.49191\n",
      "[193]\teval-merror:0.48037\ttrain-merror:0.49065\n",
      "[194]\teval-merror:0.48347\ttrain-merror:0.49122\n",
      "[195]\teval-merror:0.48347\ttrain-merror:0.49191\n",
      "[196]\teval-merror:0.48141\ttrain-merror:0.49168\n",
      "[197]\teval-merror:0.48037\ttrain-merror:0.49076\n",
      "[198]\teval-merror:0.48244\ttrain-merror:0.49122\n",
      "[199]\teval-merror:0.48347\ttrain-merror:0.49145\n",
      "[200]\teval-merror:0.48347\ttrain-merror:0.49076\n",
      "[201]\teval-merror:0.48347\ttrain-merror:0.49053\n",
      "[202]\teval-merror:0.48450\ttrain-merror:0.49076\n",
      "[203]\teval-merror:0.48244\ttrain-merror:0.49030\n",
      "[204]\teval-merror:0.48244\ttrain-merror:0.49065\n",
      "[205]\teval-merror:0.48244\ttrain-merror:0.49099\n",
      "[206]\teval-merror:0.48037\ttrain-merror:0.49030\n",
      "[207]\teval-merror:0.48141\ttrain-merror:0.49053\n",
      "[208]\teval-merror:0.48141\ttrain-merror:0.49134\n",
      "[209]\teval-merror:0.48244\ttrain-merror:0.49076\n",
      "[210]\teval-merror:0.48037\ttrain-merror:0.49030\n",
      "[211]\teval-merror:0.47831\ttrain-merror:0.48938\n",
      "[212]\teval-merror:0.48347\ttrain-merror:0.48996\n",
      "[213]\teval-merror:0.48244\ttrain-merror:0.49030\n",
      "[214]\teval-merror:0.48347\ttrain-merror:0.48996\n",
      "[215]\teval-merror:0.48244\ttrain-merror:0.48961\n",
      "[216]\teval-merror:0.48037\ttrain-merror:0.48927\n",
      "[217]\teval-merror:0.48037\ttrain-merror:0.48961\n",
      "[218]\teval-merror:0.48037\ttrain-merror:0.48938\n",
      "[219]\teval-merror:0.48037\ttrain-merror:0.48904\n",
      "[220]\teval-merror:0.48141\ttrain-merror:0.48973\n",
      "[221]\teval-merror:0.47934\ttrain-merror:0.48869\n",
      "[222]\teval-merror:0.47934\ttrain-merror:0.48869\n",
      "[223]\teval-merror:0.47934\ttrain-merror:0.48915\n",
      "[224]\teval-merror:0.47934\ttrain-merror:0.48858\n",
      "[225]\teval-merror:0.48037\ttrain-merror:0.48904\n",
      "[226]\teval-merror:0.48141\ttrain-merror:0.48915\n",
      "[227]\teval-merror:0.48141\ttrain-merror:0.48881\n",
      "[228]\teval-merror:0.48037\ttrain-merror:0.48732\n",
      "[229]\teval-merror:0.48037\ttrain-merror:0.48824\n",
      "[230]\teval-merror:0.48141\ttrain-merror:0.48835\n",
      "[231]\teval-merror:0.48141\ttrain-merror:0.48824\n",
      "[232]\teval-merror:0.48141\ttrain-merror:0.48847\n",
      "[233]\teval-merror:0.48141\ttrain-merror:0.48812\n",
      "[234]\teval-merror:0.48141\ttrain-merror:0.48766\n",
      "[235]\teval-merror:0.47934\ttrain-merror:0.48732\n",
      "[236]\teval-merror:0.48037\ttrain-merror:0.48755\n",
      "[237]\teval-merror:0.47831\ttrain-merror:0.48663\n",
      "[238]\teval-merror:0.47831\ttrain-merror:0.48651\n",
      "[239]\teval-merror:0.47934\ttrain-merror:0.48640\n",
      "[240]\teval-merror:0.47831\ttrain-merror:0.48663\n",
      "[241]\teval-merror:0.47934\ttrain-merror:0.48732\n",
      "[242]\teval-merror:0.47831\ttrain-merror:0.48709\n",
      "[243]\teval-merror:0.47727\ttrain-merror:0.48629\n",
      "[244]\teval-merror:0.47727\ttrain-merror:0.48651\n",
      "[245]\teval-merror:0.47727\ttrain-merror:0.48686\n",
      "[246]\teval-merror:0.47727\ttrain-merror:0.48709\n",
      "[247]\teval-merror:0.47624\ttrain-merror:0.48629\n",
      "[248]\teval-merror:0.47624\ttrain-merror:0.48640\n",
      "[249]\teval-merror:0.47624\ttrain-merror:0.48629\n",
      "[250]\teval-merror:0.47624\ttrain-merror:0.48479\n",
      "[251]\teval-merror:0.47521\ttrain-merror:0.48537\n",
      "[252]\teval-merror:0.47624\ttrain-merror:0.48617\n",
      "[253]\teval-merror:0.47727\ttrain-merror:0.48594\n",
      "[254]\teval-merror:0.47624\ttrain-merror:0.48594\n",
      "[255]\teval-merror:0.47624\ttrain-merror:0.48594\n",
      "[256]\teval-merror:0.47521\ttrain-merror:0.48548\n",
      "[257]\teval-merror:0.47624\ttrain-merror:0.48571\n",
      "[258]\teval-merror:0.47521\ttrain-merror:0.48594\n",
      "[259]\teval-merror:0.47314\ttrain-merror:0.48560\n",
      "[260]\teval-merror:0.47417\ttrain-merror:0.48571\n",
      "[261]\teval-merror:0.47211\ttrain-merror:0.48606\n",
      "[262]\teval-merror:0.47211\ttrain-merror:0.48502\n",
      "[263]\teval-merror:0.47417\ttrain-merror:0.48560\n",
      "[264]\teval-merror:0.47417\ttrain-merror:0.48571\n",
      "[265]\teval-merror:0.47314\ttrain-merror:0.48594\n",
      "[266]\teval-merror:0.47314\ttrain-merror:0.48651\n",
      "[267]\teval-merror:0.47314\ttrain-merror:0.48640\n",
      "[268]\teval-merror:0.47314\ttrain-merror:0.48651\n",
      "[269]\teval-merror:0.47314\ttrain-merror:0.48617\n",
      "[270]\teval-merror:0.47314\ttrain-merror:0.48606\n",
      "[271]\teval-merror:0.47314\ttrain-merror:0.48502\n",
      "[272]\teval-merror:0.47211\ttrain-merror:0.48468\n",
      "[273]\teval-merror:0.47211\ttrain-merror:0.48479\n",
      "[274]\teval-merror:0.47211\ttrain-merror:0.48479\n",
      "[275]\teval-merror:0.47417\ttrain-merror:0.48514\n",
      "[276]\teval-merror:0.47417\ttrain-merror:0.48502\n",
      "[277]\teval-merror:0.47417\ttrain-merror:0.48456\n",
      "[278]\teval-merror:0.47417\ttrain-merror:0.48456\n",
      "[279]\teval-merror:0.47417\ttrain-merror:0.48525\n",
      "[280]\teval-merror:0.47211\ttrain-merror:0.48594\n",
      "[281]\teval-merror:0.47211\ttrain-merror:0.48525\n",
      "[282]\teval-merror:0.47004\ttrain-merror:0.48548\n",
      "[283]\teval-merror:0.47211\ttrain-merror:0.48560\n",
      "[284]\teval-merror:0.47107\ttrain-merror:0.48548\n",
      "[285]\teval-merror:0.46901\ttrain-merror:0.48525\n",
      "[286]\teval-merror:0.46901\ttrain-merror:0.48456\n",
      "[287]\teval-merror:0.47004\ttrain-merror:0.48433\n",
      "[288]\teval-merror:0.47107\ttrain-merror:0.48445\n",
      "[289]\teval-merror:0.47107\ttrain-merror:0.48399\n",
      "[290]\teval-merror:0.47004\ttrain-merror:0.48399\n",
      "[291]\teval-merror:0.47004\ttrain-merror:0.48387\n",
      "[292]\teval-merror:0.46901\ttrain-merror:0.48376\n",
      "[293]\teval-merror:0.46694\ttrain-merror:0.48319\n",
      "[294]\teval-merror:0.46591\ttrain-merror:0.48319\n",
      "[295]\teval-merror:0.46797\ttrain-merror:0.48364\n",
      "[296]\teval-merror:0.46797\ttrain-merror:0.48364\n",
      "[297]\teval-merror:0.46797\ttrain-merror:0.48342\n",
      "[298]\teval-merror:0.46797\ttrain-merror:0.48364\n",
      "[299]\teval-merror:0.46797\ttrain-merror:0.48353\n",
      "[300]\teval-merror:0.46797\ttrain-merror:0.48376\n",
      "[301]\teval-merror:0.46694\ttrain-merror:0.48342\n",
      "[302]\teval-merror:0.46591\ttrain-merror:0.48296\n",
      "[303]\teval-merror:0.46694\ttrain-merror:0.48261\n",
      "[304]\teval-merror:0.46901\ttrain-merror:0.48307\n",
      "[305]\teval-merror:0.46797\ttrain-merror:0.48307\n",
      "[306]\teval-merror:0.46797\ttrain-merror:0.48330\n",
      "[307]\teval-merror:0.46797\ttrain-merror:0.48319\n",
      "[308]\teval-merror:0.46901\ttrain-merror:0.48353\n",
      "[309]\teval-merror:0.46694\ttrain-merror:0.48307\n",
      "[310]\teval-merror:0.46694\ttrain-merror:0.48319\n",
      "[311]\teval-merror:0.46797\ttrain-merror:0.48307\n",
      "[312]\teval-merror:0.46797\ttrain-merror:0.48319\n",
      "[313]\teval-merror:0.46797\ttrain-merror:0.48273\n",
      "[314]\teval-merror:0.46797\ttrain-merror:0.48284\n",
      "[315]\teval-merror:0.46591\ttrain-merror:0.48284\n",
      "[316]\teval-merror:0.46591\ttrain-merror:0.48307\n",
      "[317]\teval-merror:0.46591\ttrain-merror:0.48261\n",
      "[318]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[319]\teval-merror:0.46694\ttrain-merror:0.48261\n",
      "[320]\teval-merror:0.46591\ttrain-merror:0.48261\n",
      "[321]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[322]\teval-merror:0.46591\ttrain-merror:0.48261\n",
      "[323]\teval-merror:0.46694\ttrain-merror:0.48250\n",
      "[324]\teval-merror:0.46488\ttrain-merror:0.48273\n",
      "[325]\teval-merror:0.46591\ttrain-merror:0.48238\n",
      "[326]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[327]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[328]\teval-merror:0.46591\ttrain-merror:0.48261\n",
      "[329]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[330]\teval-merror:0.46591\ttrain-merror:0.48261\n",
      "[331]\teval-merror:0.46488\ttrain-merror:0.48296\n",
      "[332]\teval-merror:0.46591\ttrain-merror:0.48273\n",
      "[333]\teval-merror:0.46591\ttrain-merror:0.48284\n",
      "[334]\teval-merror:0.46591\ttrain-merror:0.48284\n",
      "[335]\teval-merror:0.46591\ttrain-merror:0.48250\n",
      "[336]\teval-merror:0.46488\ttrain-merror:0.48261\n",
      "[337]\teval-merror:0.46591\ttrain-merror:0.48307\n",
      "[338]\teval-merror:0.46591\ttrain-merror:0.48284\n",
      "[339]\teval-merror:0.46591\ttrain-merror:0.48342\n",
      "[340]\teval-merror:0.46488\ttrain-merror:0.48330\n",
      "[341]\teval-merror:0.46591\ttrain-merror:0.48330\n",
      "[342]\teval-merror:0.46694\ttrain-merror:0.48273\n",
      "[343]\teval-merror:0.46694\ttrain-merror:0.48284\n",
      "[344]\teval-merror:0.46591\ttrain-merror:0.48307\n",
      "[345]\teval-merror:0.46591\ttrain-merror:0.48296\n",
      "[346]\teval-merror:0.46384\ttrain-merror:0.48261\n",
      "[347]\teval-merror:0.46384\ttrain-merror:0.48307\n",
      "[348]\teval-merror:0.46384\ttrain-merror:0.48250\n",
      "[349]\teval-merror:0.46488\ttrain-merror:0.48261\n",
      "[350]\teval-merror:0.46384\ttrain-merror:0.48192\n",
      "[351]\teval-merror:0.46281\ttrain-merror:0.48158\n",
      "[352]\teval-merror:0.46384\ttrain-merror:0.48169\n",
      "[353]\teval-merror:0.46281\ttrain-merror:0.48112\n",
      "[354]\teval-merror:0.46281\ttrain-merror:0.48101\n",
      "[355]\teval-merror:0.46281\ttrain-merror:0.48101\n",
      "[356]\teval-merror:0.46281\ttrain-merror:0.48101\n",
      "[357]\teval-merror:0.46281\ttrain-merror:0.48089\n",
      "[358]\teval-merror:0.46178\ttrain-merror:0.48078\n",
      "[359]\teval-merror:0.46074\ttrain-merror:0.48101\n",
      "[360]\teval-merror:0.46074\ttrain-merror:0.48055\n",
      "[361]\teval-merror:0.46178\ttrain-merror:0.48101\n",
      "[362]\teval-merror:0.46178\ttrain-merror:0.48112\n",
      "[363]\teval-merror:0.45971\ttrain-merror:0.48101\n",
      "[364]\teval-merror:0.45971\ttrain-merror:0.48078\n",
      "[365]\teval-merror:0.45868\ttrain-merror:0.48043\n",
      "[366]\teval-merror:0.45868\ttrain-merror:0.48055\n",
      "[367]\teval-merror:0.46074\ttrain-merror:0.48032\n",
      "[368]\teval-merror:0.46178\ttrain-merror:0.48009\n",
      "[369]\teval-merror:0.45868\ttrain-merror:0.48032\n",
      "[370]\teval-merror:0.45971\ttrain-merror:0.48032\n",
      "[371]\teval-merror:0.46074\ttrain-merror:0.48078\n",
      "[372]\teval-merror:0.46074\ttrain-merror:0.48078\n",
      "[373]\teval-merror:0.46074\ttrain-merror:0.48032\n",
      "[374]\teval-merror:0.45868\ttrain-merror:0.47997\n",
      "[375]\teval-merror:0.45971\ttrain-merror:0.47986\n",
      "[376]\teval-merror:0.46074\ttrain-merror:0.48009\n",
      "[377]\teval-merror:0.46178\ttrain-merror:0.48009\n",
      "[378]\teval-merror:0.45971\ttrain-merror:0.48032\n",
      "[379]\teval-merror:0.46281\ttrain-merror:0.47997\n",
      "[380]\teval-merror:0.46281\ttrain-merror:0.48009\n",
      "[381]\teval-merror:0.45868\ttrain-merror:0.47951\n",
      "[382]\teval-merror:0.46281\ttrain-merror:0.47951\n",
      "[383]\teval-merror:0.46281\ttrain-merror:0.47951\n",
      "[384]\teval-merror:0.46178\ttrain-merror:0.47940\n",
      "[385]\teval-merror:0.46384\ttrain-merror:0.47917\n",
      "[386]\teval-merror:0.46281\ttrain-merror:0.47951\n",
      "[387]\teval-merror:0.46488\ttrain-merror:0.47883\n",
      "[388]\teval-merror:0.46281\ttrain-merror:0.47928\n",
      "[389]\teval-merror:0.46384\ttrain-merror:0.47917\n",
      "[390]\teval-merror:0.46178\ttrain-merror:0.47905\n",
      "[391]\teval-merror:0.46384\ttrain-merror:0.47883\n",
      "[392]\teval-merror:0.46384\ttrain-merror:0.47905\n",
      "[393]\teval-merror:0.46281\ttrain-merror:0.47871\n",
      "[394]\teval-merror:0.46384\ttrain-merror:0.47894\n",
      "[395]\teval-merror:0.46384\ttrain-merror:0.47894\n",
      "[396]\teval-merror:0.46488\ttrain-merror:0.47905\n",
      "[397]\teval-merror:0.46488\ttrain-merror:0.47883\n",
      "[398]\teval-merror:0.46591\ttrain-merror:0.47871\n",
      "[399]\teval-merror:0.46591\ttrain-merror:0.47905\n",
      "[400]\teval-merror:0.46591\ttrain-merror:0.47859\n",
      "[401]\teval-merror:0.46488\ttrain-merror:0.47871\n",
      "[402]\teval-merror:0.46488\ttrain-merror:0.47871\n",
      "[403]\teval-merror:0.46384\ttrain-merror:0.47859\n",
      "[404]\teval-merror:0.46488\ttrain-merror:0.47871\n",
      "[405]\teval-merror:0.46384\ttrain-merror:0.47837\n",
      "[406]\teval-merror:0.46488\ttrain-merror:0.47825\n",
      "[407]\teval-merror:0.46488\ttrain-merror:0.47837\n",
      "[408]\teval-merror:0.46488\ttrain-merror:0.47848\n",
      "[409]\teval-merror:0.46488\ttrain-merror:0.47859\n",
      "[410]\teval-merror:0.46488\ttrain-merror:0.47871\n",
      "[411]\teval-merror:0.46488\ttrain-merror:0.47859\n",
      "[412]\teval-merror:0.46488\ttrain-merror:0.47859\n",
      "[413]\teval-merror:0.46488\ttrain-merror:0.47848\n",
      "[414]\teval-merror:0.46488\ttrain-merror:0.47848\n",
      "[415]\teval-merror:0.46488\ttrain-merror:0.47814\n",
      "[416]\teval-merror:0.46488\ttrain-merror:0.47825\n",
      "[417]\teval-merror:0.46281\ttrain-merror:0.47837\n",
      "[418]\teval-merror:0.46074\ttrain-merror:0.47848\n",
      "[419]\teval-merror:0.46281\ttrain-merror:0.47825\n",
      "[420]\teval-merror:0.46178\ttrain-merror:0.47859\n",
      "[421]\teval-merror:0.46178\ttrain-merror:0.47859\n",
      "[422]\teval-merror:0.46281\ttrain-merror:0.47894\n",
      "[423]\teval-merror:0.46074\ttrain-merror:0.47883\n",
      "[424]\teval-merror:0.46178\ttrain-merror:0.47871\n",
      "[425]\teval-merror:0.46384\ttrain-merror:0.47871\n",
      "[426]\teval-merror:0.46384\ttrain-merror:0.47871\n",
      "[427]\teval-merror:0.46281\ttrain-merror:0.47859\n",
      "[428]\teval-merror:0.46384\ttrain-merror:0.47859\n",
      "[429]\teval-merror:0.46384\ttrain-merror:0.47883\n",
      "[430]\teval-merror:0.46384\ttrain-merror:0.47894\n",
      "[431]\teval-merror:0.46384\ttrain-merror:0.47871\n",
      "[432]\teval-merror:0.46281\ttrain-merror:0.47859\n",
      "[433]\teval-merror:0.46384\ttrain-merror:0.47837\n",
      "[434]\teval-merror:0.46384\ttrain-merror:0.47871\n",
      "[435]\teval-merror:0.46384\ttrain-merror:0.47871\n",
      "[436]\teval-merror:0.46281\ttrain-merror:0.47848\n",
      "[437]\teval-merror:0.46281\ttrain-merror:0.47848\n",
      "[438]\teval-merror:0.46281\ttrain-merror:0.47871\n",
      "[439]\teval-merror:0.46281\ttrain-merror:0.47871\n",
      "[440]\teval-merror:0.46384\ttrain-merror:0.47848\n",
      "[441]\teval-merror:0.46384\ttrain-merror:0.47837\n",
      "[442]\teval-merror:0.46281\ttrain-merror:0.47883\n",
      "[443]\teval-merror:0.46281\ttrain-merror:0.47825\n",
      "[444]\teval-merror:0.46178\ttrain-merror:0.47837\n",
      "[445]\teval-merror:0.46281\ttrain-merror:0.47859\n",
      "[446]\teval-merror:0.46281\ttrain-merror:0.47859\n",
      "[447]\teval-merror:0.46281\ttrain-merror:0.47859\n",
      "[448]\teval-merror:0.46281\ttrain-merror:0.47894\n",
      "[449]\teval-merror:0.46281\ttrain-merror:0.47848\n",
      "[450]\teval-merror:0.46281\ttrain-merror:0.47883\n",
      "[451]\teval-merror:0.46281\ttrain-merror:0.47883\n",
      "[452]\teval-merror:0.46281\ttrain-merror:0.47928\n",
      "[453]\teval-merror:0.46281\ttrain-merror:0.47905\n",
      "[454]\teval-merror:0.46281\ttrain-merror:0.47848\n",
      "[455]\teval-merror:0.46178\ttrain-merror:0.47848\n",
      "[456]\teval-merror:0.46178\ttrain-merror:0.47859\n",
      "[457]\teval-merror:0.46178\ttrain-merror:0.47859\n",
      "[458]\teval-merror:0.46074\ttrain-merror:0.47802\n",
      "[459]\teval-merror:0.46074\ttrain-merror:0.47814\n",
      "[460]\teval-merror:0.46178\ttrain-merror:0.47871\n",
      "[461]\teval-merror:0.46178\ttrain-merror:0.47859\n",
      "[462]\teval-merror:0.46178\ttrain-merror:0.47814\n",
      "[463]\teval-merror:0.46074\ttrain-merror:0.47848\n",
      "[464]\teval-merror:0.46074\ttrain-merror:0.47848\n",
      "[465]\teval-merror:0.46074\ttrain-merror:0.47848\n",
      "[466]\teval-merror:0.45971\ttrain-merror:0.47825\n",
      "[467]\teval-merror:0.46074\ttrain-merror:0.47848\n",
      "[468]\teval-merror:0.46074\ttrain-merror:0.47814\n",
      "[469]\teval-merror:0.46074\ttrain-merror:0.47825\n",
      "[470]\teval-merror:0.46074\ttrain-merror:0.47768\n",
      "[471]\teval-merror:0.46178\ttrain-merror:0.47791\n",
      "[472]\teval-merror:0.46074\ttrain-merror:0.47837\n",
      "[473]\teval-merror:0.46178\ttrain-merror:0.47779\n",
      "[474]\teval-merror:0.46074\ttrain-merror:0.47768\n",
      "[475]\teval-merror:0.46178\ttrain-merror:0.47779\n",
      "[476]\teval-merror:0.46178\ttrain-merror:0.47791\n",
      "[477]\teval-merror:0.46178\ttrain-merror:0.47791\n",
      "[478]\teval-merror:0.46074\ttrain-merror:0.47802\n",
      "[479]\teval-merror:0.46074\ttrain-merror:0.47768\n",
      "[480]\teval-merror:0.46281\ttrain-merror:0.47756\n",
      "[481]\teval-merror:0.46178\ttrain-merror:0.47722\n",
      "[482]\teval-merror:0.45971\ttrain-merror:0.47779\n",
      "[483]\teval-merror:0.45868\ttrain-merror:0.47756\n",
      "[484]\teval-merror:0.46074\ttrain-merror:0.47745\n",
      "[485]\teval-merror:0.45868\ttrain-merror:0.47756\n",
      "[486]\teval-merror:0.45868\ttrain-merror:0.47710\n",
      "[487]\teval-merror:0.45868\ttrain-merror:0.47745\n",
      "[488]\teval-merror:0.45868\ttrain-merror:0.47745\n",
      "[489]\teval-merror:0.45868\ttrain-merror:0.47745\n",
      "[490]\teval-merror:0.45765\ttrain-merror:0.47745\n",
      "[491]\teval-merror:0.45765\ttrain-merror:0.47791\n",
      "[492]\teval-merror:0.45868\ttrain-merror:0.47779\n",
      "[493]\teval-merror:0.45868\ttrain-merror:0.47779\n",
      "[494]\teval-merror:0.45868\ttrain-merror:0.47756\n",
      "[495]\teval-merror:0.45765\ttrain-merror:0.47768\n",
      "[496]\teval-merror:0.45765\ttrain-merror:0.47802\n",
      "[497]\teval-merror:0.45868\ttrain-merror:0.47768\n",
      "[498]\teval-merror:0.45868\ttrain-merror:0.47733\n",
      "[499]\teval-merror:0.45558\ttrain-merror:0.47756\n",
      "3\n",
      "[0]\teval-merror:0.57851\ttrain-merror:0.56559\n",
      "[1]\teval-merror:0.57851\ttrain-merror:0.56559\n",
      "[2]\teval-merror:0.57851\ttrain-merror:0.56559\n",
      "[3]\teval-merror:0.57851\ttrain-merror:0.56559\n",
      "[4]\teval-merror:0.57851\ttrain-merror:0.56559\n",
      "[5]\teval-merror:0.56715\ttrain-merror:0.55079\n",
      "[6]\teval-merror:0.54752\ttrain-merror:0.54585\n",
      "[7]\teval-merror:0.54752\ttrain-merror:0.54585\n",
      "[8]\teval-merror:0.54752\ttrain-merror:0.54585\n",
      "[9]\teval-merror:0.54752\ttrain-merror:0.54631\n",
      "[10]\teval-merror:0.54752\ttrain-merror:0.54585\n",
      "[11]\teval-merror:0.54752\ttrain-merror:0.54631\n",
      "[12]\teval-merror:0.54752\ttrain-merror:0.54631\n",
      "[13]\teval-merror:0.54752\ttrain-merror:0.54631\n",
      "[14]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[15]\teval-merror:0.54752\ttrain-merror:0.54631\n",
      "[16]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[17]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[18]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[19]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[20]\teval-merror:0.52996\ttrain-merror:0.53047\n",
      "[21]\teval-merror:0.52273\ttrain-merror:0.52175\n",
      "[22]\teval-merror:0.52273\ttrain-merror:0.52175\n",
      "[23]\teval-merror:0.52273\ttrain-merror:0.52175\n",
      "[24]\teval-merror:0.52273\ttrain-merror:0.52175\n",
      "[25]\teval-merror:0.52273\ttrain-merror:0.52186\n",
      "[26]\teval-merror:0.52273\ttrain-merror:0.52186\n",
      "[27]\teval-merror:0.52273\ttrain-merror:0.52186\n",
      "[28]\teval-merror:0.52273\ttrain-merror:0.52198\n",
      "[29]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[30]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[31]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[32]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[33]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[34]\teval-merror:0.53202\ttrain-merror:0.51899\n",
      "[35]\teval-merror:0.52273\ttrain-merror:0.52072\n",
      "[36]\teval-merror:0.53202\ttrain-merror:0.51911\n",
      "[37]\teval-merror:0.53202\ttrain-merror:0.51911\n",
      "[38]\teval-merror:0.53202\ttrain-merror:0.51899\n",
      "[39]\teval-merror:0.53202\ttrain-merror:0.51899\n",
      "[40]\teval-merror:0.53099\ttrain-merror:0.51911\n",
      "[41]\teval-merror:0.52686\ttrain-merror:0.51739\n",
      "[42]\teval-merror:0.52686\ttrain-merror:0.51739\n",
      "[43]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[44]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[45]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[46]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[47]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[48]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[49]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[50]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[51]\teval-merror:0.52789\ttrain-merror:0.51739\n",
      "[52]\teval-merror:0.52893\ttrain-merror:0.51509\n",
      "[53]\teval-merror:0.52893\ttrain-merror:0.51509\n",
      "[54]\teval-merror:0.52789\ttrain-merror:0.51567\n",
      "[55]\teval-merror:0.52789\ttrain-merror:0.51578\n",
      "[56]\teval-merror:0.52789\ttrain-merror:0.51578\n",
      "[57]\teval-merror:0.52789\ttrain-merror:0.51578\n",
      "[58]\teval-merror:0.52789\ttrain-merror:0.51234\n",
      "[59]\teval-merror:0.52789\ttrain-merror:0.51234\n",
      "[60]\teval-merror:0.52686\ttrain-merror:0.51199\n",
      "[61]\teval-merror:0.52686\ttrain-merror:0.51268\n",
      "[62]\teval-merror:0.52893\ttrain-merror:0.51291\n",
      "[63]\teval-merror:0.52893\ttrain-merror:0.51291\n",
      "[64]\teval-merror:0.52893\ttrain-merror:0.51291\n",
      "[65]\teval-merror:0.53306\ttrain-merror:0.51165\n",
      "[66]\teval-merror:0.52893\ttrain-merror:0.51188\n",
      "[67]\teval-merror:0.53306\ttrain-merror:0.51142\n",
      "[68]\teval-merror:0.53306\ttrain-merror:0.51142\n",
      "[69]\teval-merror:0.53306\ttrain-merror:0.51142\n",
      "[70]\teval-merror:0.53202\ttrain-merror:0.51107\n",
      "[71]\teval-merror:0.52893\ttrain-merror:0.50970\n",
      "[72]\teval-merror:0.53099\ttrain-merror:0.51039\n",
      "[73]\teval-merror:0.53409\ttrain-merror:0.51004\n",
      "[74]\teval-merror:0.53099\ttrain-merror:0.50970\n",
      "[75]\teval-merror:0.53409\ttrain-merror:0.50935\n",
      "[76]\teval-merror:0.53202\ttrain-merror:0.50924\n",
      "[77]\teval-merror:0.53409\ttrain-merror:0.50981\n",
      "[78]\teval-merror:0.53409\ttrain-merror:0.50901\n",
      "[79]\teval-merror:0.53409\ttrain-merror:0.50809\n",
      "[80]\teval-merror:0.53202\ttrain-merror:0.51004\n",
      "[81]\teval-merror:0.53306\ttrain-merror:0.50970\n",
      "[82]\teval-merror:0.53616\ttrain-merror:0.50648\n",
      "[83]\teval-merror:0.53616\ttrain-merror:0.50694\n",
      "[84]\teval-merror:0.53409\ttrain-merror:0.50763\n",
      "[85]\teval-merror:0.53616\ttrain-merror:0.50476\n",
      "[86]\teval-merror:0.53202\ttrain-merror:0.50568\n",
      "[87]\teval-merror:0.53099\ttrain-merror:0.50717\n",
      "[88]\teval-merror:0.53099\ttrain-merror:0.50626\n",
      "[89]\teval-merror:0.53202\ttrain-merror:0.50740\n",
      "[90]\teval-merror:0.53306\ttrain-merror:0.50545\n",
      "[91]\teval-merror:0.53409\ttrain-merror:0.50396\n",
      "[92]\teval-merror:0.53616\ttrain-merror:0.50339\n",
      "[93]\teval-merror:0.52996\ttrain-merror:0.50247\n",
      "[94]\teval-merror:0.53306\ttrain-merror:0.50339\n",
      "[95]\teval-merror:0.53306\ttrain-merror:0.50178\n",
      "[96]\teval-merror:0.53409\ttrain-merror:0.50075\n",
      "[97]\teval-merror:0.53409\ttrain-merror:0.50006\n",
      "[98]\teval-merror:0.52996\ttrain-merror:0.50086\n",
      "[99]\teval-merror:0.53099\ttrain-merror:0.49914\n",
      "[100]\teval-merror:0.53202\ttrain-merror:0.49868\n",
      "[101]\teval-merror:0.53409\ttrain-merror:0.49834\n",
      "[102]\teval-merror:0.53409\ttrain-merror:0.49937\n",
      "[103]\teval-merror:0.53202\ttrain-merror:0.49994\n",
      "[104]\teval-merror:0.53202\ttrain-merror:0.49891\n",
      "[105]\teval-merror:0.53099\ttrain-merror:0.49856\n",
      "[106]\teval-merror:0.53099\ttrain-merror:0.49868\n",
      "[107]\teval-merror:0.53099\ttrain-merror:0.49730\n",
      "[108]\teval-merror:0.53202\ttrain-merror:0.49753\n",
      "[109]\teval-merror:0.53202\ttrain-merror:0.49742\n",
      "[110]\teval-merror:0.53202\ttrain-merror:0.49834\n",
      "[111]\teval-merror:0.53099\ttrain-merror:0.49765\n",
      "[112]\teval-merror:0.53099\ttrain-merror:0.49742\n",
      "[113]\teval-merror:0.52996\ttrain-merror:0.49753\n",
      "[114]\teval-merror:0.52893\ttrain-merror:0.49765\n",
      "[115]\teval-merror:0.52893\ttrain-merror:0.49776\n",
      "[116]\teval-merror:0.52996\ttrain-merror:0.49742\n",
      "[117]\teval-merror:0.53202\ttrain-merror:0.49650\n",
      "[118]\teval-merror:0.53409\ttrain-merror:0.49604\n",
      "[119]\teval-merror:0.53099\ttrain-merror:0.49570\n",
      "[120]\teval-merror:0.53099\ttrain-merror:0.49570\n",
      "[121]\teval-merror:0.53099\ttrain-merror:0.49535\n",
      "[122]\teval-merror:0.52789\ttrain-merror:0.49639\n",
      "[123]\teval-merror:0.52893\ttrain-merror:0.49593\n",
      "[124]\teval-merror:0.52996\ttrain-merror:0.49535\n",
      "[125]\teval-merror:0.52996\ttrain-merror:0.49547\n",
      "[126]\teval-merror:0.52996\ttrain-merror:0.49558\n",
      "[127]\teval-merror:0.52893\ttrain-merror:0.49570\n",
      "[128]\teval-merror:0.52789\ttrain-merror:0.49455\n",
      "[129]\teval-merror:0.52789\ttrain-merror:0.49466\n",
      "[130]\teval-merror:0.52893\ttrain-merror:0.49535\n",
      "[131]\teval-merror:0.52893\ttrain-merror:0.49478\n",
      "[132]\teval-merror:0.52893\ttrain-merror:0.49397\n",
      "[133]\teval-merror:0.52789\ttrain-merror:0.49283\n",
      "[134]\teval-merror:0.52789\ttrain-merror:0.49271\n",
      "[135]\teval-merror:0.52789\ttrain-merror:0.49260\n",
      "[136]\teval-merror:0.52583\ttrain-merror:0.49237\n",
      "[137]\teval-merror:0.52789\ttrain-merror:0.49179\n",
      "[138]\teval-merror:0.52686\ttrain-merror:0.49179\n",
      "[139]\teval-merror:0.52789\ttrain-merror:0.49191\n",
      "[140]\teval-merror:0.52686\ttrain-merror:0.49191\n",
      "[141]\teval-merror:0.52583\ttrain-merror:0.49214\n",
      "[142]\teval-merror:0.52686\ttrain-merror:0.49191\n",
      "[143]\teval-merror:0.52066\ttrain-merror:0.49053\n",
      "[144]\teval-merror:0.52273\ttrain-merror:0.49076\n",
      "[145]\teval-merror:0.52273\ttrain-merror:0.49065\n",
      "[146]\teval-merror:0.52273\ttrain-merror:0.49053\n",
      "[147]\teval-merror:0.52376\ttrain-merror:0.48938\n",
      "[148]\teval-merror:0.52479\ttrain-merror:0.48938\n",
      "[149]\teval-merror:0.52479\ttrain-merror:0.49030\n",
      "[150]\teval-merror:0.52376\ttrain-merror:0.49019\n",
      "[151]\teval-merror:0.52479\ttrain-merror:0.49019\n",
      "[152]\teval-merror:0.52376\ttrain-merror:0.48950\n",
      "[153]\teval-merror:0.52376\ttrain-merror:0.49042\n",
      "[154]\teval-merror:0.52583\ttrain-merror:0.49053\n",
      "[155]\teval-merror:0.52479\ttrain-merror:0.49088\n",
      "[156]\teval-merror:0.52583\ttrain-merror:0.49099\n",
      "[157]\teval-merror:0.52273\ttrain-merror:0.49007\n",
      "[158]\teval-merror:0.52376\ttrain-merror:0.48950\n",
      "[159]\teval-merror:0.52169\ttrain-merror:0.48904\n",
      "[160]\teval-merror:0.52169\ttrain-merror:0.48984\n",
      "[161]\teval-merror:0.52066\ttrain-merror:0.49053\n",
      "[162]\teval-merror:0.52066\ttrain-merror:0.49019\n",
      "[163]\teval-merror:0.52066\ttrain-merror:0.49065\n",
      "[164]\teval-merror:0.52066\ttrain-merror:0.48950\n",
      "[165]\teval-merror:0.51963\ttrain-merror:0.48938\n",
      "[166]\teval-merror:0.51963\ttrain-merror:0.48961\n",
      "[167]\teval-merror:0.51963\ttrain-merror:0.48927\n",
      "[168]\teval-merror:0.52169\ttrain-merror:0.48892\n",
      "[169]\teval-merror:0.52479\ttrain-merror:0.48950\n",
      "[170]\teval-merror:0.52066\ttrain-merror:0.48938\n",
      "[171]\teval-merror:0.52376\ttrain-merror:0.48950\n",
      "[172]\teval-merror:0.52066\ttrain-merror:0.48950\n",
      "[173]\teval-merror:0.51860\ttrain-merror:0.49019\n",
      "[174]\teval-merror:0.52479\ttrain-merror:0.48996\n",
      "[175]\teval-merror:0.52169\ttrain-merror:0.48996\n",
      "[176]\teval-merror:0.52066\ttrain-merror:0.48824\n",
      "[177]\teval-merror:0.51963\ttrain-merror:0.48755\n",
      "[178]\teval-merror:0.52376\ttrain-merror:0.48732\n",
      "[179]\teval-merror:0.52273\ttrain-merror:0.48858\n",
      "[180]\teval-merror:0.52169\ttrain-merror:0.48915\n",
      "[181]\teval-merror:0.52273\ttrain-merror:0.48858\n",
      "[182]\teval-merror:0.52479\ttrain-merror:0.48927\n",
      "[183]\teval-merror:0.52376\ttrain-merror:0.48847\n",
      "[184]\teval-merror:0.52789\ttrain-merror:0.48984\n",
      "[185]\teval-merror:0.52376\ttrain-merror:0.48789\n",
      "[186]\teval-merror:0.52273\ttrain-merror:0.48651\n",
      "[187]\teval-merror:0.52273\ttrain-merror:0.48651\n",
      "[188]\teval-merror:0.52169\ttrain-merror:0.48697\n",
      "[189]\teval-merror:0.51653\ttrain-merror:0.48812\n",
      "[190]\teval-merror:0.51756\ttrain-merror:0.48789\n",
      "[191]\teval-merror:0.52273\ttrain-merror:0.48835\n",
      "[192]\teval-merror:0.52479\ttrain-merror:0.48789\n",
      "[193]\teval-merror:0.52376\ttrain-merror:0.48594\n",
      "[194]\teval-merror:0.52479\ttrain-merror:0.48606\n",
      "[195]\teval-merror:0.52479\ttrain-merror:0.48594\n",
      "[196]\teval-merror:0.52479\ttrain-merror:0.48617\n",
      "[197]\teval-merror:0.52376\ttrain-merror:0.48663\n",
      "[198]\teval-merror:0.52479\ttrain-merror:0.48755\n",
      "[199]\teval-merror:0.52479\ttrain-merror:0.48732\n",
      "[200]\teval-merror:0.52273\ttrain-merror:0.48674\n",
      "[201]\teval-merror:0.52479\ttrain-merror:0.48617\n",
      "[202]\teval-merror:0.52376\ttrain-merror:0.48606\n",
      "[203]\teval-merror:0.52686\ttrain-merror:0.48560\n",
      "[204]\teval-merror:0.52686\ttrain-merror:0.48560\n",
      "[205]\teval-merror:0.52789\ttrain-merror:0.48606\n",
      "[206]\teval-merror:0.52789\ttrain-merror:0.48617\n",
      "[207]\teval-merror:0.52583\ttrain-merror:0.48548\n",
      "[208]\teval-merror:0.52686\ttrain-merror:0.48606\n",
      "[209]\teval-merror:0.52686\ttrain-merror:0.48571\n",
      "[210]\teval-merror:0.52583\ttrain-merror:0.48537\n",
      "[211]\teval-merror:0.52583\ttrain-merror:0.48629\n",
      "[212]\teval-merror:0.52686\ttrain-merror:0.48571\n",
      "[213]\teval-merror:0.52583\ttrain-merror:0.48491\n",
      "[214]\teval-merror:0.52479\ttrain-merror:0.48468\n",
      "[215]\teval-merror:0.52479\ttrain-merror:0.48491\n",
      "[216]\teval-merror:0.52066\ttrain-merror:0.48330\n",
      "[217]\teval-merror:0.52273\ttrain-merror:0.48399\n",
      "[218]\teval-merror:0.52479\ttrain-merror:0.48422\n",
      "[219]\teval-merror:0.52376\ttrain-merror:0.48433\n",
      "[220]\teval-merror:0.52479\ttrain-merror:0.48537\n",
      "[221]\teval-merror:0.52273\ttrain-merror:0.48525\n",
      "[222]\teval-merror:0.52273\ttrain-merror:0.48491\n",
      "[223]\teval-merror:0.52273\ttrain-merror:0.48399\n",
      "[224]\teval-merror:0.52273\ttrain-merror:0.48502\n",
      "[225]\teval-merror:0.52169\ttrain-merror:0.48456\n",
      "[226]\teval-merror:0.52169\ttrain-merror:0.48456\n",
      "[227]\teval-merror:0.52273\ttrain-merror:0.48410\n",
      "[228]\teval-merror:0.52169\ttrain-merror:0.48422\n",
      "[229]\teval-merror:0.52273\ttrain-merror:0.48376\n",
      "[230]\teval-merror:0.52169\ttrain-merror:0.48399\n",
      "[231]\teval-merror:0.51963\ttrain-merror:0.48364\n",
      "[232]\teval-merror:0.52066\ttrain-merror:0.48387\n",
      "[233]\teval-merror:0.52066\ttrain-merror:0.48387\n",
      "[234]\teval-merror:0.52066\ttrain-merror:0.48387\n",
      "[235]\teval-merror:0.51860\ttrain-merror:0.48468\n",
      "[236]\teval-merror:0.51860\ttrain-merror:0.48399\n",
      "[237]\teval-merror:0.51963\ttrain-merror:0.48376\n",
      "[238]\teval-merror:0.51963\ttrain-merror:0.48342\n",
      "[239]\teval-merror:0.51756\ttrain-merror:0.48330\n",
      "[240]\teval-merror:0.51653\ttrain-merror:0.48319\n",
      "[241]\teval-merror:0.51860\ttrain-merror:0.48537\n",
      "[242]\teval-merror:0.51963\ttrain-merror:0.48433\n",
      "[243]\teval-merror:0.52066\ttrain-merror:0.48353\n",
      "[244]\teval-merror:0.51963\ttrain-merror:0.48387\n",
      "[245]\teval-merror:0.51963\ttrain-merror:0.48410\n",
      "[246]\teval-merror:0.52169\ttrain-merror:0.48399\n",
      "[247]\teval-merror:0.52169\ttrain-merror:0.48330\n",
      "[248]\teval-merror:0.51963\ttrain-merror:0.48353\n",
      "[249]\teval-merror:0.51963\ttrain-merror:0.48445\n",
      "[250]\teval-merror:0.51963\ttrain-merror:0.48422\n",
      "[251]\teval-merror:0.52066\ttrain-merror:0.48433\n",
      "[252]\teval-merror:0.52066\ttrain-merror:0.48376\n",
      "[253]\teval-merror:0.52066\ttrain-merror:0.48387\n",
      "[254]\teval-merror:0.52066\ttrain-merror:0.48422\n",
      "[255]\teval-merror:0.52066\ttrain-merror:0.48445\n",
      "[256]\teval-merror:0.52066\ttrain-merror:0.48445\n",
      "[257]\teval-merror:0.51963\ttrain-merror:0.48296\n",
      "[258]\teval-merror:0.52169\ttrain-merror:0.48342\n",
      "[259]\teval-merror:0.52273\ttrain-merror:0.48342\n",
      "[260]\teval-merror:0.51756\ttrain-merror:0.48261\n",
      "[261]\teval-merror:0.51963\ttrain-merror:0.48330\n",
      "[262]\teval-merror:0.52169\ttrain-merror:0.48364\n",
      "[263]\teval-merror:0.52066\ttrain-merror:0.48296\n",
      "[264]\teval-merror:0.51963\ttrain-merror:0.48261\n",
      "[265]\teval-merror:0.51963\ttrain-merror:0.48146\n",
      "[266]\teval-merror:0.51860\ttrain-merror:0.48158\n",
      "[267]\teval-merror:0.51963\ttrain-merror:0.48146\n",
      "[268]\teval-merror:0.51860\ttrain-merror:0.48135\n",
      "[269]\teval-merror:0.51653\ttrain-merror:0.48089\n",
      "[270]\teval-merror:0.51963\ttrain-merror:0.48181\n",
      "[271]\teval-merror:0.51653\ttrain-merror:0.48204\n",
      "[272]\teval-merror:0.51550\ttrain-merror:0.48089\n",
      "[273]\teval-merror:0.51653\ttrain-merror:0.48135\n",
      "[274]\teval-merror:0.51653\ttrain-merror:0.48112\n",
      "[275]\teval-merror:0.51653\ttrain-merror:0.48101\n",
      "[276]\teval-merror:0.51550\ttrain-merror:0.48135\n",
      "[277]\teval-merror:0.51550\ttrain-merror:0.48169\n",
      "[278]\teval-merror:0.51550\ttrain-merror:0.48192\n",
      "[279]\teval-merror:0.51550\ttrain-merror:0.48158\n",
      "[280]\teval-merror:0.51446\ttrain-merror:0.48135\n",
      "[281]\teval-merror:0.51446\ttrain-merror:0.48089\n",
      "[282]\teval-merror:0.51446\ttrain-merror:0.48066\n",
      "[283]\teval-merror:0.51446\ttrain-merror:0.48078\n",
      "[284]\teval-merror:0.51446\ttrain-merror:0.48055\n",
      "[285]\teval-merror:0.51446\ttrain-merror:0.48078\n",
      "[286]\teval-merror:0.51446\ttrain-merror:0.48032\n",
      "[287]\teval-merror:0.51343\ttrain-merror:0.48032\n",
      "[288]\teval-merror:0.51653\ttrain-merror:0.48078\n",
      "[289]\teval-merror:0.51550\ttrain-merror:0.48055\n",
      "[290]\teval-merror:0.51653\ttrain-merror:0.48089\n",
      "[291]\teval-merror:0.51550\ttrain-merror:0.48089\n",
      "[292]\teval-merror:0.51550\ttrain-merror:0.48066\n",
      "[293]\teval-merror:0.51550\ttrain-merror:0.48055\n",
      "[294]\teval-merror:0.51550\ttrain-merror:0.48043\n",
      "[295]\teval-merror:0.51343\ttrain-merror:0.48066\n",
      "[296]\teval-merror:0.51446\ttrain-merror:0.47997\n",
      "[297]\teval-merror:0.51446\ttrain-merror:0.47997\n",
      "[298]\teval-merror:0.51446\ttrain-merror:0.47963\n",
      "[299]\teval-merror:0.51343\ttrain-merror:0.47974\n",
      "[300]\teval-merror:0.51343\ttrain-merror:0.48032\n",
      "[301]\teval-merror:0.51240\ttrain-merror:0.47974\n",
      "[302]\teval-merror:0.51343\ttrain-merror:0.47928\n",
      "[303]\teval-merror:0.51240\ttrain-merror:0.47963\n",
      "[304]\teval-merror:0.51550\ttrain-merror:0.47940\n",
      "[305]\teval-merror:0.51653\ttrain-merror:0.47940\n",
      "[306]\teval-merror:0.51756\ttrain-merror:0.47917\n",
      "[307]\teval-merror:0.51550\ttrain-merror:0.47928\n",
      "[308]\teval-merror:0.51550\ttrain-merror:0.47917\n",
      "[309]\teval-merror:0.51653\ttrain-merror:0.47905\n",
      "[310]\teval-merror:0.51343\ttrain-merror:0.47917\n",
      "[311]\teval-merror:0.51240\ttrain-merror:0.47905\n",
      "[312]\teval-merror:0.51550\ttrain-merror:0.47917\n",
      "[313]\teval-merror:0.51653\ttrain-merror:0.47883\n",
      "[314]\teval-merror:0.51550\ttrain-merror:0.47859\n",
      "[315]\teval-merror:0.51550\ttrain-merror:0.47883\n",
      "[316]\teval-merror:0.51653\ttrain-merror:0.47894\n",
      "[317]\teval-merror:0.51653\ttrain-merror:0.47905\n",
      "[318]\teval-merror:0.51653\ttrain-merror:0.47894\n",
      "[319]\teval-merror:0.51653\ttrain-merror:0.47928\n",
      "[320]\teval-merror:0.51653\ttrain-merror:0.47905\n",
      "[321]\teval-merror:0.51550\ttrain-merror:0.47871\n",
      "[322]\teval-merror:0.51653\ttrain-merror:0.47859\n",
      "[323]\teval-merror:0.51343\ttrain-merror:0.47859\n",
      "[324]\teval-merror:0.51343\ttrain-merror:0.47871\n",
      "[325]\teval-merror:0.51550\ttrain-merror:0.47883\n",
      "[326]\teval-merror:0.51653\ttrain-merror:0.47859\n",
      "[327]\teval-merror:0.51550\ttrain-merror:0.47871\n",
      "[328]\teval-merror:0.51550\ttrain-merror:0.47859\n",
      "[329]\teval-merror:0.51550\ttrain-merror:0.47859\n",
      "[330]\teval-merror:0.51446\ttrain-merror:0.47894\n",
      "[331]\teval-merror:0.51550\ttrain-merror:0.47848\n",
      "[332]\teval-merror:0.51550\ttrain-merror:0.47825\n",
      "[333]\teval-merror:0.51653\ttrain-merror:0.47814\n",
      "[334]\teval-merror:0.51550\ttrain-merror:0.47837\n",
      "[335]\teval-merror:0.51550\ttrain-merror:0.47825\n",
      "[336]\teval-merror:0.51550\ttrain-merror:0.47859\n",
      "[337]\teval-merror:0.51550\ttrain-merror:0.47837\n",
      "[338]\teval-merror:0.51550\ttrain-merror:0.47837\n",
      "[339]\teval-merror:0.51653\ttrain-merror:0.47837\n",
      "[340]\teval-merror:0.51446\ttrain-merror:0.47837\n",
      "[341]\teval-merror:0.51343\ttrain-merror:0.47825\n",
      "[342]\teval-merror:0.51446\ttrain-merror:0.47779\n",
      "[343]\teval-merror:0.51446\ttrain-merror:0.47745\n",
      "[344]\teval-merror:0.51446\ttrain-merror:0.47733\n",
      "[345]\teval-merror:0.51343\ttrain-merror:0.47699\n",
      "[346]\teval-merror:0.51550\ttrain-merror:0.47768\n",
      "[347]\teval-merror:0.51550\ttrain-merror:0.47756\n",
      "[348]\teval-merror:0.51550\ttrain-merror:0.47710\n",
      "[349]\teval-merror:0.51550\ttrain-merror:0.47745\n",
      "[350]\teval-merror:0.51550\ttrain-merror:0.47722\n",
      "[351]\teval-merror:0.51550\ttrain-merror:0.47722\n",
      "[352]\teval-merror:0.51446\ttrain-merror:0.47710\n",
      "[353]\teval-merror:0.51343\ttrain-merror:0.47722\n",
      "[354]\teval-merror:0.51343\ttrain-merror:0.47733\n",
      "[355]\teval-merror:0.51343\ttrain-merror:0.47733\n",
      "[356]\teval-merror:0.51343\ttrain-merror:0.47699\n",
      "[357]\teval-merror:0.51343\ttrain-merror:0.47745\n",
      "[358]\teval-merror:0.51343\ttrain-merror:0.47733\n",
      "[359]\teval-merror:0.51343\ttrain-merror:0.47699\n",
      "[360]\teval-merror:0.51343\ttrain-merror:0.47745\n",
      "[361]\teval-merror:0.51240\ttrain-merror:0.47710\n",
      "[362]\teval-merror:0.51240\ttrain-merror:0.47653\n",
      "[363]\teval-merror:0.51240\ttrain-merror:0.47664\n",
      "[364]\teval-merror:0.51240\ttrain-merror:0.47630\n",
      "[365]\teval-merror:0.51240\ttrain-merror:0.47653\n",
      "[366]\teval-merror:0.51240\ttrain-merror:0.47699\n",
      "[367]\teval-merror:0.51240\ttrain-merror:0.47664\n",
      "[368]\teval-merror:0.51240\ttrain-merror:0.47664\n",
      "[369]\teval-merror:0.51136\ttrain-merror:0.47687\n",
      "[370]\teval-merror:0.51136\ttrain-merror:0.47676\n",
      "[371]\teval-merror:0.51136\ttrain-merror:0.47687\n",
      "[372]\teval-merror:0.51136\ttrain-merror:0.47653\n",
      "[373]\teval-merror:0.51136\ttrain-merror:0.47676\n",
      "[374]\teval-merror:0.51136\ttrain-merror:0.47619\n",
      "[375]\teval-merror:0.51136\ttrain-merror:0.47641\n",
      "[376]\teval-merror:0.51240\ttrain-merror:0.47607\n",
      "[377]\teval-merror:0.51343\ttrain-merror:0.47641\n",
      "[378]\teval-merror:0.51343\ttrain-merror:0.47619\n",
      "[379]\teval-merror:0.51343\ttrain-merror:0.47607\n",
      "[380]\teval-merror:0.51240\ttrain-merror:0.47561\n",
      "[381]\teval-merror:0.51240\ttrain-merror:0.47515\n",
      "[382]\teval-merror:0.51240\ttrain-merror:0.47527\n",
      "[383]\teval-merror:0.51240\ttrain-merror:0.47538\n",
      "[384]\teval-merror:0.51240\ttrain-merror:0.47561\n",
      "[385]\teval-merror:0.51136\ttrain-merror:0.47550\n",
      "[386]\teval-merror:0.51136\ttrain-merror:0.47538\n",
      "[387]\teval-merror:0.51136\ttrain-merror:0.47550\n",
      "[388]\teval-merror:0.51240\ttrain-merror:0.47527\n",
      "[389]\teval-merror:0.51343\ttrain-merror:0.47538\n",
      "[390]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[391]\teval-merror:0.51343\ttrain-merror:0.47504\n",
      "[392]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[393]\teval-merror:0.51240\ttrain-merror:0.47550\n",
      "[394]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[395]\teval-merror:0.51240\ttrain-merror:0.47550\n",
      "[396]\teval-merror:0.51343\ttrain-merror:0.47538\n",
      "[397]\teval-merror:0.51343\ttrain-merror:0.47504\n",
      "[398]\teval-merror:0.51343\ttrain-merror:0.47492\n",
      "[399]\teval-merror:0.51240\ttrain-merror:0.47481\n",
      "[400]\teval-merror:0.51240\ttrain-merror:0.47515\n",
      "[401]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[402]\teval-merror:0.51240\ttrain-merror:0.47481\n",
      "[403]\teval-merror:0.51343\ttrain-merror:0.47504\n",
      "[404]\teval-merror:0.51343\ttrain-merror:0.47458\n",
      "[405]\teval-merror:0.51343\ttrain-merror:0.47469\n",
      "[406]\teval-merror:0.51343\ttrain-merror:0.47469\n",
      "[407]\teval-merror:0.51446\ttrain-merror:0.47446\n",
      "[408]\teval-merror:0.51343\ttrain-merror:0.47550\n",
      "[409]\teval-merror:0.51343\ttrain-merror:0.47527\n",
      "[410]\teval-merror:0.51343\ttrain-merror:0.47458\n",
      "[411]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[412]\teval-merror:0.51240\ttrain-merror:0.47515\n",
      "[413]\teval-merror:0.51136\ttrain-merror:0.47446\n",
      "[414]\teval-merror:0.51343\ttrain-merror:0.47504\n",
      "[415]\teval-merror:0.51343\ttrain-merror:0.47469\n",
      "[416]\teval-merror:0.51343\ttrain-merror:0.47515\n",
      "[417]\teval-merror:0.51240\ttrain-merror:0.47561\n",
      "[418]\teval-merror:0.51240\ttrain-merror:0.47527\n",
      "[419]\teval-merror:0.51446\ttrain-merror:0.47515\n",
      "[420]\teval-merror:0.51446\ttrain-merror:0.47504\n",
      "[421]\teval-merror:0.51343\ttrain-merror:0.47481\n",
      "[422]\teval-merror:0.51343\ttrain-merror:0.47481\n",
      "[423]\teval-merror:0.51240\ttrain-merror:0.47435\n",
      "[424]\teval-merror:0.51240\ttrain-merror:0.47446\n",
      "[425]\teval-merror:0.51240\ttrain-merror:0.47458\n",
      "[426]\teval-merror:0.51240\ttrain-merror:0.47435\n",
      "[427]\teval-merror:0.51343\ttrain-merror:0.47446\n",
      "[428]\teval-merror:0.51343\ttrain-merror:0.47435\n",
      "[429]\teval-merror:0.51240\ttrain-merror:0.47423\n",
      "[430]\teval-merror:0.51240\ttrain-merror:0.47423\n",
      "[431]\teval-merror:0.51240\ttrain-merror:0.47423\n",
      "[432]\teval-merror:0.51343\ttrain-merror:0.47423\n",
      "[433]\teval-merror:0.51343\ttrain-merror:0.47412\n",
      "[434]\teval-merror:0.51343\ttrain-merror:0.47400\n",
      "[435]\teval-merror:0.51343\ttrain-merror:0.47458\n",
      "[436]\teval-merror:0.51343\ttrain-merror:0.47400\n",
      "[437]\teval-merror:0.51343\ttrain-merror:0.47423\n",
      "[438]\teval-merror:0.51343\ttrain-merror:0.47423\n",
      "[439]\teval-merror:0.51343\ttrain-merror:0.47400\n",
      "[440]\teval-merror:0.51343\ttrain-merror:0.47412\n",
      "[441]\teval-merror:0.51343\ttrain-merror:0.47435\n",
      "[442]\teval-merror:0.51343\ttrain-merror:0.47378\n",
      "[443]\teval-merror:0.51343\ttrain-merror:0.47412\n",
      "[444]\teval-merror:0.51343\ttrain-merror:0.47400\n",
      "[445]\teval-merror:0.51446\ttrain-merror:0.47446\n",
      "[446]\teval-merror:0.51550\ttrain-merror:0.47458\n",
      "[447]\teval-merror:0.51550\ttrain-merror:0.47481\n",
      "[448]\teval-merror:0.51550\ttrain-merror:0.47481\n",
      "[449]\teval-merror:0.51550\ttrain-merror:0.47389\n",
      "[450]\teval-merror:0.51550\ttrain-merror:0.47412\n",
      "[451]\teval-merror:0.51550\ttrain-merror:0.47435\n",
      "[452]\teval-merror:0.51446\ttrain-merror:0.47423\n",
      "[453]\teval-merror:0.51550\ttrain-merror:0.47435\n",
      "[454]\teval-merror:0.51343\ttrain-merror:0.47458\n",
      "[455]\teval-merror:0.51343\ttrain-merror:0.47423\n",
      "[456]\teval-merror:0.51343\ttrain-merror:0.47423\n",
      "[457]\teval-merror:0.51136\ttrain-merror:0.47320\n",
      "[458]\teval-merror:0.51240\ttrain-merror:0.47320\n",
      "[459]\teval-merror:0.51240\ttrain-merror:0.47332\n",
      "[460]\teval-merror:0.51240\ttrain-merror:0.47320\n",
      "[461]\teval-merror:0.51343\ttrain-merror:0.47309\n",
      "[462]\teval-merror:0.51550\ttrain-merror:0.47332\n",
      "[463]\teval-merror:0.51343\ttrain-merror:0.47332\n",
      "[464]\teval-merror:0.51446\ttrain-merror:0.47286\n",
      "[465]\teval-merror:0.51343\ttrain-merror:0.47343\n",
      "[466]\teval-merror:0.51240\ttrain-merror:0.47274\n",
      "[467]\teval-merror:0.51240\ttrain-merror:0.47251\n",
      "[468]\teval-merror:0.51240\ttrain-merror:0.47263\n",
      "[469]\teval-merror:0.51343\ttrain-merror:0.47297\n",
      "[470]\teval-merror:0.51240\ttrain-merror:0.47274\n",
      "[471]\teval-merror:0.51343\ttrain-merror:0.47309\n",
      "[472]\teval-merror:0.51240\ttrain-merror:0.47297\n",
      "[473]\teval-merror:0.51240\ttrain-merror:0.47332\n",
      "[474]\teval-merror:0.51136\ttrain-merror:0.47354\n",
      "[475]\teval-merror:0.51240\ttrain-merror:0.47320\n",
      "[476]\teval-merror:0.51240\ttrain-merror:0.47343\n",
      "[477]\teval-merror:0.51240\ttrain-merror:0.47354\n",
      "[478]\teval-merror:0.51136\ttrain-merror:0.47354\n",
      "[479]\teval-merror:0.51240\ttrain-merror:0.47332\n",
      "[480]\teval-merror:0.51136\ttrain-merror:0.47332\n",
      "[481]\teval-merror:0.51136\ttrain-merror:0.47343\n",
      "[482]\teval-merror:0.51240\ttrain-merror:0.47297\n",
      "[483]\teval-merror:0.51136\ttrain-merror:0.47309\n",
      "[484]\teval-merror:0.51136\ttrain-merror:0.47354\n",
      "[485]\teval-merror:0.51136\ttrain-merror:0.47343\n",
      "[486]\teval-merror:0.50930\ttrain-merror:0.47309\n",
      "[487]\teval-merror:0.50930\ttrain-merror:0.47343\n",
      "[488]\teval-merror:0.51033\ttrain-merror:0.47309\n",
      "[489]\teval-merror:0.51033\ttrain-merror:0.47297\n",
      "[490]\teval-merror:0.51033\ttrain-merror:0.47354\n",
      "[491]\teval-merror:0.51033\ttrain-merror:0.47354\n",
      "[492]\teval-merror:0.51033\ttrain-merror:0.47343\n",
      "[493]\teval-merror:0.51033\ttrain-merror:0.47354\n",
      "[494]\teval-merror:0.51240\ttrain-merror:0.47343\n",
      "[495]\teval-merror:0.51240\ttrain-merror:0.47343\n",
      "[496]\teval-merror:0.51240\ttrain-merror:0.47366\n",
      "[497]\teval-merror:0.51240\ttrain-merror:0.47343\n",
      "[498]\teval-merror:0.51033\ttrain-merror:0.47343\n",
      "[499]\teval-merror:0.51136\ttrain-merror:0.47366\n",
      "4\n",
      "[0]\teval-merror:0.56302\ttrain-merror:0.56731\n",
      "[1]\teval-merror:0.56302\ttrain-merror:0.56731\n",
      "[2]\teval-merror:0.56302\ttrain-merror:0.56731\n",
      "[3]\teval-merror:0.56302\ttrain-merror:0.56731\n",
      "[4]\teval-merror:0.54959\ttrain-merror:0.54493\n",
      "[5]\teval-merror:0.54959\ttrain-merror:0.54493\n",
      "[6]\teval-merror:0.54855\ttrain-merror:0.54470\n",
      "[7]\teval-merror:0.54546\ttrain-merror:0.54562\n",
      "[8]\teval-merror:0.54442\ttrain-merror:0.54562\n",
      "[9]\teval-merror:0.54855\ttrain-merror:0.54470\n",
      "[10]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[11]\teval-merror:0.54029\ttrain-merror:0.54711\n",
      "[12]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[13]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[14]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[15]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[16]\teval-merror:0.53306\ttrain-merror:0.53919\n",
      "[17]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[18]\teval-merror:0.53202\ttrain-merror:0.53965\n",
      "[19]\teval-merror:0.54132\ttrain-merror:0.54654\n",
      "[20]\teval-merror:0.51860\ttrain-merror:0.53162\n",
      "[21]\teval-merror:0.51860\ttrain-merror:0.53162\n",
      "[22]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[23]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[24]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[25]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[26]\teval-merror:0.50620\ttrain-merror:0.52244\n",
      "[27]\teval-merror:0.50620\ttrain-merror:0.52244\n",
      "[28]\teval-merror:0.50620\ttrain-merror:0.52244\n",
      "[29]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[30]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[31]\teval-merror:0.50620\ttrain-merror:0.52244\n",
      "[32]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[33]\teval-merror:0.50620\ttrain-merror:0.52244\n",
      "[34]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[35]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[36]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[37]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[38]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[39]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[40]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[41]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[42]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[43]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[44]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[45]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[46]\teval-merror:0.50620\ttrain-merror:0.52232\n",
      "[47]\teval-merror:0.50620\ttrain-merror:0.52255\n",
      "[48]\teval-merror:0.50620\ttrain-merror:0.52267\n",
      "[49]\teval-merror:0.50620\ttrain-merror:0.52267\n",
      "[50]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[51]\teval-merror:0.50620\ttrain-merror:0.52267\n",
      "[52]\teval-merror:0.50620\ttrain-merror:0.52267\n",
      "[53]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[54]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[55]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[56]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[57]\teval-merror:0.50413\ttrain-merror:0.52278\n",
      "[58]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[59]\teval-merror:0.50620\ttrain-merror:0.52301\n",
      "[60]\teval-merror:0.50413\ttrain-merror:0.52244\n",
      "[61]\teval-merror:0.50930\ttrain-merror:0.51532\n",
      "[62]\teval-merror:0.50930\ttrain-merror:0.51532\n",
      "[63]\teval-merror:0.50930\ttrain-merror:0.51532\n",
      "[64]\teval-merror:0.51033\ttrain-merror:0.51590\n",
      "[65]\teval-merror:0.50930\ttrain-merror:0.51521\n",
      "[66]\teval-merror:0.51033\ttrain-merror:0.51532\n",
      "[67]\teval-merror:0.51033\ttrain-merror:0.51544\n",
      "[68]\teval-merror:0.51033\ttrain-merror:0.51578\n",
      "[69]\teval-merror:0.51033\ttrain-merror:0.51578\n",
      "[70]\teval-merror:0.51033\ttrain-merror:0.51578\n",
      "[71]\teval-merror:0.51033\ttrain-merror:0.51590\n",
      "[72]\teval-merror:0.51033\ttrain-merror:0.51578\n",
      "[73]\teval-merror:0.50930\ttrain-merror:0.51555\n",
      "[74]\teval-merror:0.50930\ttrain-merror:0.51452\n",
      "[75]\teval-merror:0.50930\ttrain-merror:0.51406\n",
      "[76]\teval-merror:0.50930\ttrain-merror:0.51349\n",
      "[77]\teval-merror:0.50930\ttrain-merror:0.51360\n",
      "[78]\teval-merror:0.50930\ttrain-merror:0.51406\n",
      "[79]\teval-merror:0.50826\ttrain-merror:0.51349\n",
      "[80]\teval-merror:0.50930\ttrain-merror:0.51360\n",
      "[81]\teval-merror:0.50826\ttrain-merror:0.51234\n",
      "[82]\teval-merror:0.50826\ttrain-merror:0.51349\n",
      "[83]\teval-merror:0.50826\ttrain-merror:0.51337\n",
      "[84]\teval-merror:0.50826\ttrain-merror:0.51326\n",
      "[85]\teval-merror:0.50826\ttrain-merror:0.51234\n",
      "[86]\teval-merror:0.50723\ttrain-merror:0.51222\n",
      "[87]\teval-merror:0.50310\ttrain-merror:0.51165\n",
      "[88]\teval-merror:0.50103\ttrain-merror:0.51107\n",
      "[89]\teval-merror:0.50103\ttrain-merror:0.51107\n",
      "[90]\teval-merror:0.50000\ttrain-merror:0.51016\n",
      "[91]\teval-merror:0.49793\ttrain-merror:0.50981\n",
      "[92]\teval-merror:0.50207\ttrain-merror:0.50867\n",
      "[93]\teval-merror:0.50620\ttrain-merror:0.50786\n",
      "[94]\teval-merror:0.50516\ttrain-merror:0.50694\n",
      "[95]\teval-merror:0.50310\ttrain-merror:0.50763\n",
      "[96]\teval-merror:0.50310\ttrain-merror:0.50648\n",
      "[97]\teval-merror:0.50413\ttrain-merror:0.50602\n",
      "[98]\teval-merror:0.50310\ttrain-merror:0.50626\n",
      "[99]\teval-merror:0.49897\ttrain-merror:0.50648\n",
      "[100]\teval-merror:0.50310\ttrain-merror:0.50648\n",
      "[101]\teval-merror:0.50310\ttrain-merror:0.50614\n",
      "[102]\teval-merror:0.50310\ttrain-merror:0.50660\n",
      "[103]\teval-merror:0.50103\ttrain-merror:0.50522\n",
      "[104]\teval-merror:0.50207\ttrain-merror:0.50580\n",
      "[105]\teval-merror:0.49793\ttrain-merror:0.50350\n",
      "[106]\teval-merror:0.49793\ttrain-merror:0.50407\n",
      "[107]\teval-merror:0.49690\ttrain-merror:0.50373\n",
      "[108]\teval-merror:0.49897\ttrain-merror:0.50557\n",
      "[109]\teval-merror:0.49793\ttrain-merror:0.50362\n",
      "[110]\teval-merror:0.49484\ttrain-merror:0.50591\n",
      "[111]\teval-merror:0.49587\ttrain-merror:0.50178\n",
      "[112]\teval-merror:0.49484\ttrain-merror:0.50316\n",
      "[113]\teval-merror:0.49484\ttrain-merror:0.50281\n",
      "[114]\teval-merror:0.49380\ttrain-merror:0.50270\n",
      "[115]\teval-merror:0.49587\ttrain-merror:0.50166\n",
      "[116]\teval-merror:0.49587\ttrain-merror:0.50212\n",
      "[117]\teval-merror:0.49380\ttrain-merror:0.50063\n",
      "[118]\teval-merror:0.49484\ttrain-merror:0.50075\n",
      "[119]\teval-merror:0.49484\ttrain-merror:0.50029\n",
      "[120]\teval-merror:0.49690\ttrain-merror:0.50052\n",
      "[121]\teval-merror:0.49587\ttrain-merror:0.50029\n",
      "[122]\teval-merror:0.49793\ttrain-merror:0.50143\n",
      "[123]\teval-merror:0.49793\ttrain-merror:0.50098\n",
      "[124]\teval-merror:0.49793\ttrain-merror:0.50098\n",
      "[125]\teval-merror:0.49690\ttrain-merror:0.49983\n",
      "[126]\teval-merror:0.49690\ttrain-merror:0.49960\n",
      "[127]\teval-merror:0.49690\ttrain-merror:0.49891\n",
      "[128]\teval-merror:0.49690\ttrain-merror:0.49879\n",
      "[129]\teval-merror:0.49587\ttrain-merror:0.49902\n",
      "[130]\teval-merror:0.49690\ttrain-merror:0.49891\n",
      "[131]\teval-merror:0.49690\ttrain-merror:0.49902\n",
      "[132]\teval-merror:0.49690\ttrain-merror:0.49902\n",
      "[133]\teval-merror:0.49690\ttrain-merror:0.49856\n",
      "[134]\teval-merror:0.49587\ttrain-merror:0.49822\n",
      "[135]\teval-merror:0.49690\ttrain-merror:0.49822\n",
      "[136]\teval-merror:0.49793\ttrain-merror:0.49811\n",
      "[137]\teval-merror:0.49690\ttrain-merror:0.49822\n",
      "[138]\teval-merror:0.49690\ttrain-merror:0.49845\n",
      "[139]\teval-merror:0.49587\ttrain-merror:0.49822\n",
      "[140]\teval-merror:0.48554\ttrain-merror:0.49570\n",
      "[141]\teval-merror:0.48554\ttrain-merror:0.49593\n",
      "[142]\teval-merror:0.48554\ttrain-merror:0.49581\n",
      "[143]\teval-merror:0.48554\ttrain-merror:0.49535\n",
      "[144]\teval-merror:0.48554\ttrain-merror:0.49524\n",
      "[145]\teval-merror:0.48657\ttrain-merror:0.49547\n",
      "[146]\teval-merror:0.48864\ttrain-merror:0.49581\n",
      "[147]\teval-merror:0.48657\ttrain-merror:0.49547\n",
      "[148]\teval-merror:0.48760\ttrain-merror:0.49570\n",
      "[149]\teval-merror:0.48760\ttrain-merror:0.49512\n",
      "[150]\teval-merror:0.48554\ttrain-merror:0.49661\n",
      "[151]\teval-merror:0.48554\ttrain-merror:0.49535\n",
      "[152]\teval-merror:0.48657\ttrain-merror:0.49639\n",
      "[153]\teval-merror:0.48657\ttrain-merror:0.49616\n",
      "[154]\teval-merror:0.48554\ttrain-merror:0.49604\n",
      "[155]\teval-merror:0.48657\ttrain-merror:0.49661\n",
      "[156]\teval-merror:0.48657\ttrain-merror:0.49604\n",
      "[157]\teval-merror:0.48554\ttrain-merror:0.49547\n",
      "[158]\teval-merror:0.48760\ttrain-merror:0.49570\n",
      "[159]\teval-merror:0.48760\ttrain-merror:0.49581\n",
      "[160]\teval-merror:0.48864\ttrain-merror:0.49570\n",
      "[161]\teval-merror:0.48864\ttrain-merror:0.49581\n",
      "[162]\teval-merror:0.48967\ttrain-merror:0.49581\n",
      "[163]\teval-merror:0.48967\ttrain-merror:0.49616\n",
      "[164]\teval-merror:0.48760\ttrain-merror:0.49547\n",
      "[165]\teval-merror:0.48967\ttrain-merror:0.49673\n",
      "[166]\teval-merror:0.48967\ttrain-merror:0.49570\n",
      "[167]\teval-merror:0.48864\ttrain-merror:0.49570\n",
      "[168]\teval-merror:0.48864\ttrain-merror:0.49570\n",
      "[169]\teval-merror:0.48657\ttrain-merror:0.49581\n",
      "[170]\teval-merror:0.48760\ttrain-merror:0.49650\n",
      "[171]\teval-merror:0.48864\ttrain-merror:0.49616\n",
      "[172]\teval-merror:0.48864\ttrain-merror:0.49547\n",
      "[173]\teval-merror:0.48864\ttrain-merror:0.49524\n",
      "[174]\teval-merror:0.48967\ttrain-merror:0.49547\n",
      "[175]\teval-merror:0.48967\ttrain-merror:0.49547\n",
      "[176]\teval-merror:0.49070\ttrain-merror:0.49547\n",
      "[177]\teval-merror:0.49070\ttrain-merror:0.49535\n",
      "[178]\teval-merror:0.49070\ttrain-merror:0.49570\n",
      "[179]\teval-merror:0.49070\ttrain-merror:0.49570\n",
      "[180]\teval-merror:0.48864\ttrain-merror:0.49489\n",
      "[181]\teval-merror:0.48967\ttrain-merror:0.49478\n",
      "[182]\teval-merror:0.48864\ttrain-merror:0.49466\n",
      "[183]\teval-merror:0.48864\ttrain-merror:0.49466\n",
      "[184]\teval-merror:0.49070\ttrain-merror:0.49420\n",
      "[185]\teval-merror:0.48967\ttrain-merror:0.49443\n",
      "[186]\teval-merror:0.49174\ttrain-merror:0.49374\n",
      "[187]\teval-merror:0.49174\ttrain-merror:0.49397\n",
      "[188]\teval-merror:0.49277\ttrain-merror:0.49306\n",
      "[189]\teval-merror:0.49277\ttrain-merror:0.49294\n",
      "[190]\teval-merror:0.49380\ttrain-merror:0.49329\n",
      "[191]\teval-merror:0.49380\ttrain-merror:0.49329\n",
      "[192]\teval-merror:0.49484\ttrain-merror:0.49260\n",
      "[193]\teval-merror:0.49484\ttrain-merror:0.49283\n",
      "[194]\teval-merror:0.49484\ttrain-merror:0.49317\n",
      "[195]\teval-merror:0.49484\ttrain-merror:0.49329\n",
      "[196]\teval-merror:0.49587\ttrain-merror:0.49329\n",
      "[197]\teval-merror:0.49277\ttrain-merror:0.49294\n",
      "[198]\teval-merror:0.49484\ttrain-merror:0.49317\n",
      "[199]\teval-merror:0.49380\ttrain-merror:0.49260\n",
      "[200]\teval-merror:0.49380\ttrain-merror:0.49306\n",
      "[201]\teval-merror:0.49484\ttrain-merror:0.49260\n",
      "[202]\teval-merror:0.49484\ttrain-merror:0.49237\n",
      "[203]\teval-merror:0.49484\ttrain-merror:0.49202\n",
      "[204]\teval-merror:0.49587\ttrain-merror:0.49214\n",
      "[205]\teval-merror:0.49793\ttrain-merror:0.49111\n",
      "[206]\teval-merror:0.49793\ttrain-merror:0.49145\n",
      "[207]\teval-merror:0.49690\ttrain-merror:0.49145\n",
      "[208]\teval-merror:0.49587\ttrain-merror:0.49145\n",
      "[209]\teval-merror:0.49587\ttrain-merror:0.49122\n",
      "[210]\teval-merror:0.49690\ttrain-merror:0.49134\n",
      "[211]\teval-merror:0.49793\ttrain-merror:0.49145\n",
      "[212]\teval-merror:0.49690\ttrain-merror:0.49111\n",
      "[213]\teval-merror:0.49690\ttrain-merror:0.49019\n",
      "[214]\teval-merror:0.49690\ttrain-merror:0.49019\n",
      "[215]\teval-merror:0.49587\ttrain-merror:0.49042\n",
      "[216]\teval-merror:0.49587\ttrain-merror:0.49007\n",
      "[217]\teval-merror:0.49587\ttrain-merror:0.48984\n",
      "[218]\teval-merror:0.49484\ttrain-merror:0.49007\n",
      "[219]\teval-merror:0.49690\ttrain-merror:0.48973\n",
      "[220]\teval-merror:0.49690\ttrain-merror:0.48892\n",
      "[221]\teval-merror:0.49793\ttrain-merror:0.48927\n",
      "[222]\teval-merror:0.49897\ttrain-merror:0.48950\n",
      "[223]\teval-merror:0.49380\ttrain-merror:0.48869\n",
      "[224]\teval-merror:0.49690\ttrain-merror:0.48927\n",
      "[225]\teval-merror:0.49484\ttrain-merror:0.48892\n",
      "[226]\teval-merror:0.49793\ttrain-merror:0.48915\n",
      "[227]\teval-merror:0.49793\ttrain-merror:0.48847\n",
      "[228]\teval-merror:0.49793\ttrain-merror:0.48835\n",
      "[229]\teval-merror:0.50000\ttrain-merror:0.48858\n",
      "[230]\teval-merror:0.50000\ttrain-merror:0.48801\n",
      "[231]\teval-merror:0.50000\ttrain-merror:0.48812\n",
      "[232]\teval-merror:0.49793\ttrain-merror:0.48801\n",
      "[233]\teval-merror:0.49587\ttrain-merror:0.48743\n",
      "[234]\teval-merror:0.49690\ttrain-merror:0.48778\n",
      "[235]\teval-merror:0.49587\ttrain-merror:0.48778\n",
      "[236]\teval-merror:0.49587\ttrain-merror:0.48743\n",
      "[237]\teval-merror:0.49897\ttrain-merror:0.48789\n",
      "[238]\teval-merror:0.50103\ttrain-merror:0.48720\n",
      "[239]\teval-merror:0.49897\ttrain-merror:0.48755\n",
      "[240]\teval-merror:0.49793\ttrain-merror:0.48651\n",
      "[241]\teval-merror:0.49484\ttrain-merror:0.48686\n",
      "[242]\teval-merror:0.49793\ttrain-merror:0.48629\n",
      "[243]\teval-merror:0.49690\ttrain-merror:0.48720\n",
      "[244]\teval-merror:0.49690\ttrain-merror:0.48629\n",
      "[245]\teval-merror:0.49793\ttrain-merror:0.48663\n",
      "[246]\teval-merror:0.49690\ttrain-merror:0.48606\n",
      "[247]\teval-merror:0.49380\ttrain-merror:0.48606\n",
      "[248]\teval-merror:0.49277\ttrain-merror:0.48617\n",
      "[249]\teval-merror:0.49380\ttrain-merror:0.48571\n",
      "[250]\teval-merror:0.49587\ttrain-merror:0.48583\n",
      "[251]\teval-merror:0.49277\ttrain-merror:0.48606\n",
      "[252]\teval-merror:0.49277\ttrain-merror:0.48606\n",
      "[253]\teval-merror:0.49690\ttrain-merror:0.48617\n",
      "[254]\teval-merror:0.49690\ttrain-merror:0.48594\n",
      "[255]\teval-merror:0.49587\ttrain-merror:0.48502\n",
      "[256]\teval-merror:0.49484\ttrain-merror:0.48479\n",
      "[257]\teval-merror:0.49897\ttrain-merror:0.48502\n",
      "[258]\teval-merror:0.49897\ttrain-merror:0.48491\n",
      "[259]\teval-merror:0.49793\ttrain-merror:0.48491\n",
      "[260]\teval-merror:0.49587\ttrain-merror:0.48560\n",
      "[261]\teval-merror:0.49484\ttrain-merror:0.48422\n",
      "[262]\teval-merror:0.49277\ttrain-merror:0.48410\n",
      "[263]\teval-merror:0.49277\ttrain-merror:0.48387\n",
      "[264]\teval-merror:0.49174\ttrain-merror:0.48422\n",
      "[265]\teval-merror:0.49277\ttrain-merror:0.48353\n",
      "[266]\teval-merror:0.49277\ttrain-merror:0.48342\n",
      "[267]\teval-merror:0.49277\ttrain-merror:0.48422\n",
      "[268]\teval-merror:0.49484\ttrain-merror:0.48319\n",
      "[269]\teval-merror:0.49380\ttrain-merror:0.48307\n",
      "[270]\teval-merror:0.49380\ttrain-merror:0.48376\n",
      "[271]\teval-merror:0.49277\ttrain-merror:0.48410\n",
      "[272]\teval-merror:0.49380\ttrain-merror:0.48353\n",
      "[273]\teval-merror:0.49484\ttrain-merror:0.48250\n",
      "[274]\teval-merror:0.49484\ttrain-merror:0.48273\n",
      "[275]\teval-merror:0.49174\ttrain-merror:0.48284\n",
      "[276]\teval-merror:0.49484\ttrain-merror:0.48192\n",
      "[277]\teval-merror:0.49484\ttrain-merror:0.48215\n",
      "[278]\teval-merror:0.49587\ttrain-merror:0.48250\n",
      "[279]\teval-merror:0.49587\ttrain-merror:0.48296\n",
      "[280]\teval-merror:0.49380\ttrain-merror:0.48307\n",
      "[281]\teval-merror:0.49484\ttrain-merror:0.48227\n",
      "[282]\teval-merror:0.49484\ttrain-merror:0.48227\n",
      "[283]\teval-merror:0.49587\ttrain-merror:0.48204\n",
      "[284]\teval-merror:0.49587\ttrain-merror:0.48146\n",
      "[285]\teval-merror:0.49587\ttrain-merror:0.48089\n",
      "[286]\teval-merror:0.49587\ttrain-merror:0.48124\n",
      "[287]\teval-merror:0.49587\ttrain-merror:0.48043\n",
      "[288]\teval-merror:0.49380\ttrain-merror:0.48032\n",
      "[289]\teval-merror:0.49277\ttrain-merror:0.48020\n",
      "[290]\teval-merror:0.49380\ttrain-merror:0.48020\n",
      "[291]\teval-merror:0.49380\ttrain-merror:0.48055\n",
      "[292]\teval-merror:0.49277\ttrain-merror:0.48101\n",
      "[293]\teval-merror:0.49277\ttrain-merror:0.48101\n",
      "[294]\teval-merror:0.49277\ttrain-merror:0.48089\n",
      "[295]\teval-merror:0.49277\ttrain-merror:0.47986\n",
      "[296]\teval-merror:0.49277\ttrain-merror:0.48032\n",
      "[297]\teval-merror:0.49174\ttrain-merror:0.47940\n",
      "[298]\teval-merror:0.49277\ttrain-merror:0.47951\n",
      "[299]\teval-merror:0.49380\ttrain-merror:0.47997\n",
      "[300]\teval-merror:0.49277\ttrain-merror:0.47986\n",
      "[301]\teval-merror:0.49380\ttrain-merror:0.48032\n",
      "[302]\teval-merror:0.49277\ttrain-merror:0.47986\n",
      "[303]\teval-merror:0.49380\ttrain-merror:0.47963\n",
      "[304]\teval-merror:0.49277\ttrain-merror:0.47986\n",
      "[305]\teval-merror:0.49277\ttrain-merror:0.47928\n",
      "[306]\teval-merror:0.49174\ttrain-merror:0.48009\n",
      "[307]\teval-merror:0.49277\ttrain-merror:0.48066\n",
      "[308]\teval-merror:0.49277\ttrain-merror:0.48043\n",
      "[309]\teval-merror:0.49277\ttrain-merror:0.48032\n",
      "[310]\teval-merror:0.49277\ttrain-merror:0.48078\n",
      "[311]\teval-merror:0.49277\ttrain-merror:0.48043\n",
      "[312]\teval-merror:0.49380\ttrain-merror:0.48009\n",
      "[313]\teval-merror:0.49380\ttrain-merror:0.47963\n",
      "[314]\teval-merror:0.49380\ttrain-merror:0.47974\n",
      "[315]\teval-merror:0.49277\ttrain-merror:0.47974\n",
      "[316]\teval-merror:0.49277\ttrain-merror:0.47905\n",
      "[317]\teval-merror:0.49174\ttrain-merror:0.47894\n",
      "[318]\teval-merror:0.49174\ttrain-merror:0.47917\n",
      "[319]\teval-merror:0.49174\ttrain-merror:0.47905\n",
      "[320]\teval-merror:0.49174\ttrain-merror:0.47871\n",
      "[321]\teval-merror:0.49277\ttrain-merror:0.47859\n",
      "[322]\teval-merror:0.49277\ttrain-merror:0.47859\n",
      "[323]\teval-merror:0.49174\ttrain-merror:0.47825\n",
      "[324]\teval-merror:0.49174\ttrain-merror:0.47825\n",
      "[325]\teval-merror:0.49070\ttrain-merror:0.47859\n",
      "[326]\teval-merror:0.49174\ttrain-merror:0.47883\n",
      "[327]\teval-merror:0.49174\ttrain-merror:0.47859\n",
      "[328]\teval-merror:0.49070\ttrain-merror:0.47859\n",
      "[329]\teval-merror:0.49070\ttrain-merror:0.47837\n",
      "[330]\teval-merror:0.49070\ttrain-merror:0.47859\n",
      "[331]\teval-merror:0.49070\ttrain-merror:0.47871\n",
      "[332]\teval-merror:0.49070\ttrain-merror:0.47825\n",
      "[333]\teval-merror:0.49070\ttrain-merror:0.47814\n",
      "[334]\teval-merror:0.49070\ttrain-merror:0.47859\n",
      "[335]\teval-merror:0.49070\ttrain-merror:0.47883\n",
      "[336]\teval-merror:0.49070\ttrain-merror:0.47871\n",
      "[337]\teval-merror:0.48967\ttrain-merror:0.47859\n",
      "[338]\teval-merror:0.48967\ttrain-merror:0.47883\n",
      "[339]\teval-merror:0.48967\ttrain-merror:0.47871\n",
      "[340]\teval-merror:0.48967\ttrain-merror:0.47859\n",
      "[341]\teval-merror:0.49070\ttrain-merror:0.47871\n",
      "[342]\teval-merror:0.48967\ttrain-merror:0.47928\n",
      "[343]\teval-merror:0.48967\ttrain-merror:0.47905\n",
      "[344]\teval-merror:0.48967\ttrain-merror:0.47837\n",
      "[345]\teval-merror:0.48967\ttrain-merror:0.47814\n",
      "[346]\teval-merror:0.48967\ttrain-merror:0.47802\n",
      "[347]\teval-merror:0.48967\ttrain-merror:0.47825\n",
      "[348]\teval-merror:0.48864\ttrain-merror:0.47848\n",
      "[349]\teval-merror:0.48760\ttrain-merror:0.47722\n",
      "[350]\teval-merror:0.48760\ttrain-merror:0.47768\n",
      "[351]\teval-merror:0.48864\ttrain-merror:0.47802\n",
      "[352]\teval-merror:0.48760\ttrain-merror:0.47814\n",
      "[353]\teval-merror:0.48760\ttrain-merror:0.47802\n",
      "[354]\teval-merror:0.48657\ttrain-merror:0.47814\n",
      "[355]\teval-merror:0.48657\ttrain-merror:0.47837\n",
      "[356]\teval-merror:0.48554\ttrain-merror:0.47825\n",
      "[357]\teval-merror:0.48554\ttrain-merror:0.47802\n",
      "[358]\teval-merror:0.48554\ttrain-merror:0.47814\n",
      "[359]\teval-merror:0.48657\ttrain-merror:0.47802\n",
      "[360]\teval-merror:0.48554\ttrain-merror:0.47779\n",
      "[361]\teval-merror:0.48657\ttrain-merror:0.47837\n",
      "[362]\teval-merror:0.48554\ttrain-merror:0.47859\n",
      "[363]\teval-merror:0.48450\ttrain-merror:0.47837\n",
      "[364]\teval-merror:0.48450\ttrain-merror:0.47779\n",
      "[365]\teval-merror:0.48450\ttrain-merror:0.47802\n",
      "[366]\teval-merror:0.48450\ttrain-merror:0.47768\n",
      "[367]\teval-merror:0.48450\ttrain-merror:0.47768\n",
      "[368]\teval-merror:0.48450\ttrain-merror:0.47756\n",
      "[369]\teval-merror:0.48450\ttrain-merror:0.47722\n",
      "[370]\teval-merror:0.48554\ttrain-merror:0.47791\n",
      "[371]\teval-merror:0.48450\ttrain-merror:0.47733\n",
      "[372]\teval-merror:0.48554\ttrain-merror:0.47779\n",
      "[373]\teval-merror:0.48554\ttrain-merror:0.47825\n",
      "[374]\teval-merror:0.48554\ttrain-merror:0.47825\n",
      "[375]\teval-merror:0.48450\ttrain-merror:0.47802\n",
      "[376]\teval-merror:0.48554\ttrain-merror:0.47802\n",
      "[377]\teval-merror:0.48450\ttrain-merror:0.47779\n",
      "[378]\teval-merror:0.48450\ttrain-merror:0.47779\n",
      "[379]\teval-merror:0.48657\ttrain-merror:0.47745\n",
      "[380]\teval-merror:0.48554\ttrain-merror:0.47814\n",
      "[381]\teval-merror:0.48554\ttrain-merror:0.47802\n",
      "[382]\teval-merror:0.48657\ttrain-merror:0.47825\n",
      "[383]\teval-merror:0.48657\ttrain-merror:0.47837\n",
      "[384]\teval-merror:0.48554\ttrain-merror:0.47814\n",
      "[385]\teval-merror:0.48657\ttrain-merror:0.47814\n",
      "[386]\teval-merror:0.48760\ttrain-merror:0.47802\n",
      "[387]\teval-merror:0.48760\ttrain-merror:0.47791\n",
      "[388]\teval-merror:0.48760\ttrain-merror:0.47814\n",
      "[389]\teval-merror:0.48760\ttrain-merror:0.47779\n",
      "[390]\teval-merror:0.48760\ttrain-merror:0.47779\n",
      "[391]\teval-merror:0.48760\ttrain-merror:0.47791\n",
      "[392]\teval-merror:0.48657\ttrain-merror:0.47802\n",
      "[393]\teval-merror:0.48554\ttrain-merror:0.47768\n",
      "[394]\teval-merror:0.48554\ttrain-merror:0.47791\n",
      "[395]\teval-merror:0.48554\ttrain-merror:0.47768\n",
      "[396]\teval-merror:0.48554\ttrain-merror:0.47779\n",
      "[397]\teval-merror:0.48554\ttrain-merror:0.47791\n",
      "[398]\teval-merror:0.48554\ttrain-merror:0.47791\n",
      "[399]\teval-merror:0.48760\ttrain-merror:0.47722\n",
      "[400]\teval-merror:0.48760\ttrain-merror:0.47733\n",
      "[401]\teval-merror:0.48864\ttrain-merror:0.47756\n",
      "[402]\teval-merror:0.48760\ttrain-merror:0.47687\n",
      "[403]\teval-merror:0.48864\ttrain-merror:0.47676\n",
      "[404]\teval-merror:0.48760\ttrain-merror:0.47676\n",
      "[405]\teval-merror:0.48760\ttrain-merror:0.47687\n",
      "[406]\teval-merror:0.48760\ttrain-merror:0.47664\n",
      "[407]\teval-merror:0.48657\ttrain-merror:0.47710\n",
      "[408]\teval-merror:0.48657\ttrain-merror:0.47768\n",
      "[409]\teval-merror:0.48657\ttrain-merror:0.47710\n",
      "[410]\teval-merror:0.48657\ttrain-merror:0.47756\n",
      "[411]\teval-merror:0.48554\ttrain-merror:0.47722\n",
      "[412]\teval-merror:0.48554\ttrain-merror:0.47699\n",
      "[413]\teval-merror:0.48554\ttrain-merror:0.47722\n",
      "[414]\teval-merror:0.48760\ttrain-merror:0.47710\n",
      "[415]\teval-merror:0.48657\ttrain-merror:0.47687\n",
      "[416]\teval-merror:0.48864\ttrain-merror:0.47756\n",
      "[417]\teval-merror:0.48967\ttrain-merror:0.47791\n",
      "[418]\teval-merror:0.48864\ttrain-merror:0.47745\n",
      "[419]\teval-merror:0.48760\ttrain-merror:0.47802\n",
      "[420]\teval-merror:0.48967\ttrain-merror:0.47768\n",
      "[421]\teval-merror:0.48967\ttrain-merror:0.47756\n",
      "[422]\teval-merror:0.49070\ttrain-merror:0.47745\n",
      "[423]\teval-merror:0.49070\ttrain-merror:0.47733\n",
      "[424]\teval-merror:0.49070\ttrain-merror:0.47699\n",
      "[425]\teval-merror:0.48864\ttrain-merror:0.47687\n",
      "[426]\teval-merror:0.49070\ttrain-merror:0.47710\n",
      "[427]\teval-merror:0.48967\ttrain-merror:0.47756\n",
      "[428]\teval-merror:0.48967\ttrain-merror:0.47733\n",
      "[429]\teval-merror:0.48967\ttrain-merror:0.47699\n",
      "[430]\teval-merror:0.49070\ttrain-merror:0.47687\n",
      "[431]\teval-merror:0.48864\ttrain-merror:0.47676\n",
      "[432]\teval-merror:0.48864\ttrain-merror:0.47699\n",
      "[433]\teval-merror:0.48864\ttrain-merror:0.47699\n",
      "[434]\teval-merror:0.48864\ttrain-merror:0.47722\n",
      "[435]\teval-merror:0.48760\ttrain-merror:0.47710\n",
      "[436]\teval-merror:0.48864\ttrain-merror:0.47687\n",
      "[437]\teval-merror:0.48864\ttrain-merror:0.47733\n",
      "[438]\teval-merror:0.48760\ttrain-merror:0.47722\n",
      "[439]\teval-merror:0.48657\ttrain-merror:0.47745\n",
      "[440]\teval-merror:0.48760\ttrain-merror:0.47733\n",
      "[441]\teval-merror:0.48554\ttrain-merror:0.47676\n",
      "[442]\teval-merror:0.48760\ttrain-merror:0.47653\n",
      "[443]\teval-merror:0.48967\ttrain-merror:0.47676\n",
      "[444]\teval-merror:0.48967\ttrain-merror:0.47710\n",
      "[445]\teval-merror:0.48967\ttrain-merror:0.47699\n",
      "[446]\teval-merror:0.48760\ttrain-merror:0.47699\n",
      "[447]\teval-merror:0.48967\ttrain-merror:0.47641\n",
      "[448]\teval-merror:0.48760\ttrain-merror:0.47619\n",
      "[449]\teval-merror:0.48760\ttrain-merror:0.47653\n",
      "[450]\teval-merror:0.48760\ttrain-merror:0.47607\n",
      "[451]\teval-merror:0.48760\ttrain-merror:0.47607\n",
      "[452]\teval-merror:0.48760\ttrain-merror:0.47596\n",
      "[453]\teval-merror:0.48864\ttrain-merror:0.47527\n",
      "[454]\teval-merror:0.48864\ttrain-merror:0.47561\n",
      "[455]\teval-merror:0.48864\ttrain-merror:0.47538\n",
      "[456]\teval-merror:0.48864\ttrain-merror:0.47550\n",
      "[457]\teval-merror:0.48864\ttrain-merror:0.47550\n",
      "[458]\teval-merror:0.48864\ttrain-merror:0.47573\n",
      "[459]\teval-merror:0.48657\ttrain-merror:0.47527\n",
      "[460]\teval-merror:0.48760\ttrain-merror:0.47527\n",
      "[461]\teval-merror:0.48760\ttrain-merror:0.47504\n",
      "[462]\teval-merror:0.48760\ttrain-merror:0.47481\n",
      "[463]\teval-merror:0.48760\ttrain-merror:0.47527\n",
      "[464]\teval-merror:0.48554\ttrain-merror:0.47504\n",
      "[465]\teval-merror:0.48657\ttrain-merror:0.47515\n",
      "[466]\teval-merror:0.48657\ttrain-merror:0.47469\n",
      "[467]\teval-merror:0.48864\ttrain-merror:0.47504\n",
      "[468]\teval-merror:0.48967\ttrain-merror:0.47573\n",
      "[469]\teval-merror:0.48864\ttrain-merror:0.47561\n",
      "[470]\teval-merror:0.48864\ttrain-merror:0.47527\n",
      "[471]\teval-merror:0.48864\ttrain-merror:0.47538\n",
      "[472]\teval-merror:0.48864\ttrain-merror:0.47504\n",
      "[473]\teval-merror:0.48864\ttrain-merror:0.47492\n",
      "[474]\teval-merror:0.48864\ttrain-merror:0.47504\n",
      "[475]\teval-merror:0.48967\ttrain-merror:0.47481\n",
      "[476]\teval-merror:0.48760\ttrain-merror:0.47458\n",
      "[477]\teval-merror:0.48967\ttrain-merror:0.47527\n",
      "[478]\teval-merror:0.48864\ttrain-merror:0.47504\n",
      "[479]\teval-merror:0.48760\ttrain-merror:0.47469\n",
      "[480]\teval-merror:0.48864\ttrain-merror:0.47492\n",
      "[481]\teval-merror:0.48864\ttrain-merror:0.47481\n",
      "[482]\teval-merror:0.48864\ttrain-merror:0.47504\n",
      "[483]\teval-merror:0.48967\ttrain-merror:0.47481\n",
      "[484]\teval-merror:0.48760\ttrain-merror:0.47481\n",
      "[485]\teval-merror:0.48760\ttrain-merror:0.47481\n",
      "[486]\teval-merror:0.48760\ttrain-merror:0.47481\n",
      "[487]\teval-merror:0.48760\ttrain-merror:0.47458\n",
      "[488]\teval-merror:0.48760\ttrain-merror:0.47446\n",
      "[489]\teval-merror:0.48967\ttrain-merror:0.47481\n",
      "[490]\teval-merror:0.48760\ttrain-merror:0.47435\n",
      "[491]\teval-merror:0.48967\ttrain-merror:0.47446\n",
      "[492]\teval-merror:0.48967\ttrain-merror:0.47446\n",
      "[493]\teval-merror:0.48967\ttrain-merror:0.47458\n",
      "[494]\teval-merror:0.48864\ttrain-merror:0.47492\n",
      "[495]\teval-merror:0.48967\ttrain-merror:0.47469\n",
      "[496]\teval-merror:0.48864\ttrain-merror:0.47481\n",
      "[497]\teval-merror:0.48864\ttrain-merror:0.47423\n",
      "[498]\teval-merror:0.48864\ttrain-merror:0.47458\n",
      "[499]\teval-merror:0.48864\ttrain-merror:0.47446\n",
      "5\n",
      "[0]\teval-merror:0.57645\ttrain-merror:0.56582\n",
      "[1]\teval-merror:0.57748\ttrain-merror:0.54241\n",
      "[2]\teval-merror:0.57748\ttrain-merror:0.54241\n",
      "[3]\teval-merror:0.57748\ttrain-merror:0.54241\n",
      "[4]\teval-merror:0.57748\ttrain-merror:0.54241\n",
      "[5]\teval-merror:0.57748\ttrain-merror:0.54241\n",
      "[6]\teval-merror:0.57438\ttrain-merror:0.54287\n",
      "[7]\teval-merror:0.57438\ttrain-merror:0.54287\n",
      "[8]\teval-merror:0.57438\ttrain-merror:0.54287\n",
      "[9]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[10]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[11]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[12]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[13]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[14]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[15]\teval-merror:0.57748\ttrain-merror:0.54298\n",
      "[16]\teval-merror:0.55165\ttrain-merror:0.52806\n",
      "[17]\teval-merror:0.55165\ttrain-merror:0.52806\n",
      "[18]\teval-merror:0.55165\ttrain-merror:0.52806\n",
      "[19]\teval-merror:0.55165\ttrain-merror:0.52806\n",
      "[20]\teval-merror:0.55165\ttrain-merror:0.52806\n",
      "[21]\teval-merror:0.55165\ttrain-merror:0.52818\n",
      "[22]\teval-merror:0.54752\ttrain-merror:0.51899\n",
      "[23]\teval-merror:0.54752\ttrain-merror:0.51911\n",
      "[24]\teval-merror:0.54752\ttrain-merror:0.51911\n",
      "[25]\teval-merror:0.54752\ttrain-merror:0.51911\n",
      "[26]\teval-merror:0.54752\ttrain-merror:0.51899\n",
      "[27]\teval-merror:0.54752\ttrain-merror:0.51899\n",
      "[28]\teval-merror:0.54855\ttrain-merror:0.51785\n",
      "[29]\teval-merror:0.54855\ttrain-merror:0.51785\n",
      "[30]\teval-merror:0.54855\ttrain-merror:0.51785\n",
      "[31]\teval-merror:0.54649\ttrain-merror:0.51899\n",
      "[32]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[33]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[34]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[35]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[36]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[37]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[38]\teval-merror:0.54752\ttrain-merror:0.51773\n",
      "[39]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[40]\teval-merror:0.54752\ttrain-merror:0.51773\n",
      "[41]\teval-merror:0.54752\ttrain-merror:0.51785\n",
      "[42]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[43]\teval-merror:0.54752\ttrain-merror:0.51773\n",
      "[44]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[45]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[46]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[47]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[48]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[49]\teval-merror:0.54752\ttrain-merror:0.51819\n",
      "[50]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[51]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[52]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[53]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[54]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[55]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[56]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[57]\teval-merror:0.54855\ttrain-merror:0.51750\n",
      "[58]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[59]\teval-merror:0.54752\ttrain-merror:0.51808\n",
      "[60]\teval-merror:0.54855\ttrain-merror:0.51750\n",
      "[61]\teval-merror:0.54855\ttrain-merror:0.51750\n",
      "[62]\teval-merror:0.55062\ttrain-merror:0.51773\n",
      "[63]\teval-merror:0.55062\ttrain-merror:0.51773\n",
      "[64]\teval-merror:0.54855\ttrain-merror:0.51750\n",
      "[65]\teval-merror:0.55062\ttrain-merror:0.51773\n",
      "[66]\teval-merror:0.55062\ttrain-merror:0.51647\n",
      "[67]\teval-merror:0.55062\ttrain-merror:0.51647\n",
      "[68]\teval-merror:0.55062\ttrain-merror:0.51647\n",
      "[69]\teval-merror:0.55062\ttrain-merror:0.51670\n",
      "[70]\teval-merror:0.55062\ttrain-merror:0.51681\n",
      "[71]\teval-merror:0.55062\ttrain-merror:0.51658\n",
      "[72]\teval-merror:0.54649\ttrain-merror:0.50935\n",
      "[73]\teval-merror:0.54649\ttrain-merror:0.50958\n",
      "[74]\teval-merror:0.54649\ttrain-merror:0.50935\n",
      "[75]\teval-merror:0.54649\ttrain-merror:0.50912\n",
      "[76]\teval-merror:0.54649\ttrain-merror:0.50912\n",
      "[77]\teval-merror:0.54649\ttrain-merror:0.50935\n",
      "[78]\teval-merror:0.54649\ttrain-merror:0.50912\n",
      "[79]\teval-merror:0.54442\ttrain-merror:0.50809\n",
      "[80]\teval-merror:0.54442\ttrain-merror:0.50821\n",
      "[81]\teval-merror:0.54442\ttrain-merror:0.50821\n",
      "[82]\teval-merror:0.54339\ttrain-merror:0.50775\n",
      "[83]\teval-merror:0.54236\ttrain-merror:0.50717\n",
      "[84]\teval-merror:0.54236\ttrain-merror:0.50717\n",
      "[85]\teval-merror:0.54236\ttrain-merror:0.50717\n",
      "[86]\teval-merror:0.54236\ttrain-merror:0.50717\n",
      "[87]\teval-merror:0.54029\ttrain-merror:0.50660\n",
      "[88]\teval-merror:0.54029\ttrain-merror:0.50683\n",
      "[89]\teval-merror:0.54029\ttrain-merror:0.50671\n",
      "[90]\teval-merror:0.53822\ttrain-merror:0.50648\n",
      "[91]\teval-merror:0.54029\ttrain-merror:0.50671\n",
      "[92]\teval-merror:0.54132\ttrain-merror:0.50534\n",
      "[93]\teval-merror:0.54029\ttrain-merror:0.50522\n",
      "[94]\teval-merror:0.54029\ttrain-merror:0.50522\n",
      "[95]\teval-merror:0.53926\ttrain-merror:0.50476\n",
      "[96]\teval-merror:0.53616\ttrain-merror:0.50373\n",
      "[97]\teval-merror:0.53616\ttrain-merror:0.50350\n",
      "[98]\teval-merror:0.53719\ttrain-merror:0.50384\n",
      "[99]\teval-merror:0.53719\ttrain-merror:0.50407\n",
      "[100]\teval-merror:0.53616\ttrain-merror:0.50396\n",
      "[101]\teval-merror:0.53616\ttrain-merror:0.50316\n",
      "[102]\teval-merror:0.53409\ttrain-merror:0.50155\n",
      "[103]\teval-merror:0.53719\ttrain-merror:0.50189\n",
      "[104]\teval-merror:0.53616\ttrain-merror:0.50189\n",
      "[105]\teval-merror:0.53512\ttrain-merror:0.50132\n",
      "[106]\teval-merror:0.53616\ttrain-merror:0.50121\n",
      "[107]\teval-merror:0.53512\ttrain-merror:0.50121\n",
      "[108]\teval-merror:0.53409\ttrain-merror:0.50052\n",
      "[109]\teval-merror:0.53306\ttrain-merror:0.50086\n",
      "[110]\teval-merror:0.53099\ttrain-merror:0.50040\n",
      "[111]\teval-merror:0.53099\ttrain-merror:0.50029\n",
      "[112]\teval-merror:0.52893\ttrain-merror:0.49925\n",
      "[113]\teval-merror:0.52789\ttrain-merror:0.49856\n",
      "[114]\teval-merror:0.52789\ttrain-merror:0.49845\n",
      "[115]\teval-merror:0.52893\ttrain-merror:0.49856\n",
      "[116]\teval-merror:0.53202\ttrain-merror:0.49856\n",
      "[117]\teval-merror:0.52996\ttrain-merror:0.49742\n",
      "[118]\teval-merror:0.53202\ttrain-merror:0.49776\n",
      "[119]\teval-merror:0.53099\ttrain-merror:0.49742\n",
      "[120]\teval-merror:0.53409\ttrain-merror:0.49673\n",
      "[121]\teval-merror:0.53306\ttrain-merror:0.49696\n",
      "[122]\teval-merror:0.53306\ttrain-merror:0.49742\n",
      "[123]\teval-merror:0.53099\ttrain-merror:0.49639\n",
      "[124]\teval-merror:0.52996\ttrain-merror:0.49616\n",
      "[125]\teval-merror:0.52893\ttrain-merror:0.49684\n",
      "[126]\teval-merror:0.52893\ttrain-merror:0.49593\n",
      "[127]\teval-merror:0.52893\ttrain-merror:0.49604\n",
      "[128]\teval-merror:0.52893\ttrain-merror:0.49604\n",
      "[129]\teval-merror:0.52789\ttrain-merror:0.49616\n",
      "[130]\teval-merror:0.52583\ttrain-merror:0.49489\n",
      "[131]\teval-merror:0.52893\ttrain-merror:0.49581\n",
      "[132]\teval-merror:0.52686\ttrain-merror:0.49616\n",
      "[133]\teval-merror:0.52893\ttrain-merror:0.49639\n",
      "[134]\teval-merror:0.52789\ttrain-merror:0.49524\n",
      "[135]\teval-merror:0.52376\ttrain-merror:0.49374\n",
      "[136]\teval-merror:0.52583\ttrain-merror:0.49409\n",
      "[137]\teval-merror:0.52686\ttrain-merror:0.49351\n",
      "[138]\teval-merror:0.52583\ttrain-merror:0.49409\n",
      "[139]\teval-merror:0.52583\ttrain-merror:0.49374\n",
      "[140]\teval-merror:0.52583\ttrain-merror:0.49283\n",
      "[141]\teval-merror:0.52479\ttrain-merror:0.49317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4ef5d76fa3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_train_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_kf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdtest_kf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mypred_test_kf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ad1f2621bc56>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(X_train, y_train, dtest, max_depth, n, eta, gamma)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'objective'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'multi:softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     98\u001b[0m                                \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                                evaluation_result_list=evaluation_result_list))\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEarlyStopException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mperiod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_iteration\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_iteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_fmt_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_stdv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mrabit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%d]\\t%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/rabit.py\u001b[0m in \u001b[0;36mtracker_print\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    414\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    415\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "list_max_depth = list(np.arange(1, 10))\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "kf_accuracy = []\n",
    "depth_average = []\n",
    "depth_std = []\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for max_depth in list_max_depth: \n",
    "    print(max_depth)\n",
    "    i=0\n",
    "    accuracy_depth = []\n",
    "    for train, test in kf.split(X_train):\n",
    "        i+=1\n",
    "        print(i)\n",
    "        X_train_kf, X_test_kf = X[train],X[test]\n",
    "        y_train_kf, y_test_kf = y[train],y[test]\n",
    "        dtest_kf = xgb.DMatrix(X_test_kf, label=y_test_kf)\n",
    "        bst = run_model(X_train_kf, y_train_kf, dtest_kf, max_depth, 500, 0.05, 3)\n",
    "        \n",
    "        ypred_test_kf = bst.predict(dtest_kf)\n",
    "        \n",
    "        accuracy_depth.append(accuracy_score(y_test_kf, ypred_test_kf))\n",
    "    depth_average.append(np.mean(accuracy_depth))\n",
    "    depth_std.append(np.std(accuracy_depth))\n",
    "    print(np.mean(accuracy_depth))\n",
    "    print(np.std(accuracy_depth))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0.5470513607791964\n",
      "0.01051779508003816\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0.5496324062465352\n",
      "0.015368771698125694\n",
      "20\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0.545503586384532\n",
      "0.016978688963971582\n",
      "30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0.5479800467381384\n",
      "0.013312788310295575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "list_max_depth = [10,15,20,30]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf_accuracy = []\n",
    "depth_average = []\n",
    "depth_std = []\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for max_depth in list_max_depth: \n",
    "    print(max_depth)\n",
    "    i=0\n",
    "    accuracy_depth = []\n",
    "    for train, test in kf.split(X_train):\n",
    "        i+=1\n",
    "        print(i)\n",
    "        X_train_kf, X_test_kf = X[train],X[test]\n",
    "        y_train_kf, y_test_kf = y[train],y[test]\n",
    "        dtest_kf = xgb.DMatrix(X_test_kf, label=y_test_kf)\n",
    "        bst = run_model(X_train_kf, y_train_kf, dtest_kf, max_depth, 500, 0.05, 3)\n",
    "        \n",
    "        ypred_test_kf = bst.predict(dtest_kf)\n",
    "        \n",
    "        accuracy_depth.append(accuracy_score(y_test_kf, ypred_test_kf))\n",
    "    depth_average.append(np.mean(accuracy_depth))\n",
    "    depth_std.append(np.std(accuracy_depth))\n",
    "    print(np.mean(accuracy_depth))\n",
    "    print(np.std(accuracy_depth))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5378557836306463\n",
      "0.011655390436133391\n",
      "0.03\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5367205933176036\n",
      "0.012740217456145156\n",
      "0.05\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5441577031875995\n",
      "0.010055953790141724\n",
      "0.08\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.544882443669814\n",
      "0.009240580016642986\n",
      "0.1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5478775114452357\n",
      "0.0043657265540191365\n",
      "0.15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5394057970705316\n",
      "0.010085658014785722\n",
      "0.2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5446752987707838\n",
      "0.009366878964517903\n",
      "0.3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5402345366652871\n",
      "0.006143923676897405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "eta_list = [0.01,0.03,0.05,0.08,0.1,0.15,0.2,0.3]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf_accuracy = []\n",
    "eta_average = []\n",
    "eta_std = []\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for eta in eta_list: \n",
    "    eta_acc = []\n",
    "    print(eta)\n",
    "    i = 0\n",
    "    for train, test in kf.split(X_train):\n",
    "        i += 1\n",
    "        print(i)\n",
    "        X_train_kf, X_test_kf = X[train],X[test]\n",
    "        y_train_kf, y_test_kf = y[train],y[test]\n",
    "        dtest_kf = xgb.DMatrix(X_test_kf, label=y_test_kf)\n",
    "        bst = run_model(X_train_kf, y_train_kf, dtest_kf, 9, 500, eta, 3)\n",
    "        \n",
    "        ypred_test_kf = bst.predict(dtest_kf)\n",
    "        \n",
    "        eta_acc.append(accuracy_score(y_test_kf, ypred_test_kf))\n",
    "    eta_average.append(np.mean(eta_acc))\n",
    "    eta_std.append(np.std(eta_acc))\n",
    "    print(np.mean(eta_acc))\n",
    "    print(np.std(eta_acc))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "20\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gamma_list = [0.1, 0.5, 1, 2, 3, 5, 10, 20]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf_accuracy = []\n",
    "gamma_average = []\n",
    "gamma_std = []\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for gamma in gamma_list: \n",
    "    gamma_acc = []\n",
    "    print(gamma)\n",
    "    i = 0\n",
    "    for train, test in kf.split(X_train):\n",
    "        i += 1\n",
    "        print(i)\n",
    "        X_train_kf, X_test_kf = X[train],X[test]\n",
    "        y_train_kf, y_test_kf = y[train],y[test]\n",
    "        dtest_kf = xgb.DMatrix(X_test_kf, label=y_test_kf)\n",
    "        bst = run_model(X_train_kf, y_train_kf, dtest_kf, 9, 500, 0.1, gamma)\n",
    "        \n",
    "        ypred_test_kf = bst.predict(dtest_kf)\n",
    "        \n",
    "        gamma_acc.append(accuracy_score(y_test_kf, ypred_test_kf))\n",
    "    gamma_average.append(np.mean(gamma_acc))\n",
    "    gamma_std.append(np.std(gamma_acc))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.54002669843884\n",
      "0.0067653539255491755\n",
      "100\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5498410146900079\n",
      "0.008648237748934787\n",
      "150\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5451922543594294\n",
      "0.01184628812182647\n",
      "200\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5456054774999253\n",
      "0.004375576541929194\n",
      "300\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5495300306770716\n",
      "0.00494489188119057\n",
      "500\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5474638083088358\n",
      "0.008416848807576097\n",
      "1000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.5488077435072554\n",
      "0.007623773182216662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_list = [50, 100, 150, 200, 300, 500, 1000]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf_accuracy = []\n",
    "num_average = []\n",
    "num_std = []\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for num in num_list: \n",
    "    num_acc = []\n",
    "    print(num)\n",
    "    i = 0\n",
    "    for train, test in kf.split(X_train):\n",
    "        i += 1\n",
    "        print(i)\n",
    "        X_train_kf, X_test_kf = X[train],X[test]\n",
    "        y_train_kf, y_test_kf = y[train],y[test]\n",
    "        dtest_kf = xgb.DMatrix(X_test_kf, label=y_test_kf)\n",
    "        bst = run_model(X_train_kf, y_train_kf, dtest_kf, 9, num, 0.1, 1)\n",
    "        \n",
    "        ypred_test_kf = bst.predict(dtest_kf)\n",
    "        \n",
    "        num_acc.append(accuracy_score(y_test_kf, ypred_test_kf))\n",
    "    num_average.append(np.mean(num_acc))\n",
    "    num_std.append(np.std(num_acc))\n",
    "    print(np.mean(num_acc))\n",
    "    print(np.std(num_acc))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_average)\n",
    "print(num_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5435386684700291, 0.5468454669186823, 0.5555216595485052, 0.5507708200890018, 0.5446761520968355, 0.5351710598736223, 0.5213295246547229, 0.49685042687635733]\n",
      "[0.008893955808184516, 0.00677154390976767, 0.01482358598231383, 0.009587511417490114, 0.007899094264232616, 0.011115974834526863, 0.015282207799057305, 0.00585652658851566]\n"
     ]
    }
   ],
   "source": [
    "print(gamma_average)\n",
    "print(gamma_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eta_average)\n",
    "print(eta_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth_average)\n",
    "print(depth_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = run_model(X_train, y_train, dtest, 9, 300, 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 1. 3. ... 3. 3. 1.]\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "ypred_train = bst.predict(dtrain)\n",
    "print(ypred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9250077471335606"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, ypred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_test = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPDElEQVR4nO3dbYwdV33H8e8PO4SHFJHIm9S13dqVLFoHiZKu3NBICDVIcQHhvCCSkQALpbKKQgttJWrzolFfWMqLClGqhsoCWiMokQWosQJpGxkiVKlNunloiWPcrAiNt3HjhYqHPijU4d8XdyLdbu7au3fWu3t9vh9pNTNnztxzzh75d8czd+6mqpAkteFla90BSdLqMfQlqSGGviQ1xNCXpIYY+pLUkI1r3YGL2bRpU23fvn2tuyFJE+WRRx75blVNLSxf96G/fft2ZmZm1robkjRRkvzrqHIv70hSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkPW/RO5mgzbD35lzdr+zl1vX7O218pa/b5b/F1fbjzTl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSEXDf0kn0lyLskTQ2XXJHkgyVPd8uqhfYeSzCY5neSWofJfTvLNbt8nkmTlhyNJupClnOn/BbBnQdlB4ERV7QROdNsk2QXsA67vjrk7yYbumE8CB4Cd3c/C15QkXWIX/ctZVfWNJNsXFO8F3tKtHwUeBH6/K7+nqp4Hnk4yC+xO8h3gNVX19wBJPgvcCtzfewQX4F8XkqT/b9xr+tdV1VmAbnltV74FODNUb64r29KtLywfKcmBJDNJZubn58fsoiRpoZW+kTvqOn1doHykqjpSVdNVNT01NbVinZOk1o0b+s8l2QzQLc915XPAtqF6W4Fnu/KtI8olSato3NA/Duzv1vcD9w6V70tyZZIdDG7YPtxdAvpRkhu7T+28b+gYSdIqueiN3CRfYHDTdlOSOeBO4C7gWJLbgWeA2wCq6mSSY8CTwHngjqp6oXupDzD4JNArGdzAvaQ3cSVJL7WUT++8e5FdNy9S/zBweET5DPD6ZfVOkrSifCJXkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNeSiH9mUpJZdbl/c6Jm+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqSK/QT/I7SU4meSLJF5K8Isk1SR5I8lS3vHqo/qEks0lOJ7mlf/clScsxdugn2QL8NjBdVa8HNgD7gIPAiaraCZzotkmyq9t/PbAHuDvJhn7dlyQtR9/LOxuBVybZCLwKeBbYCxzt9h8Fbu3W9wL3VNXzVfU0MAvs7tm+JGkZxg79qvo34I+AZ4CzwA+q6m+B66rqbFfnLHBtd8gW4MzQS8x1ZS+R5ECSmSQz8/Pz43ZRkrRAn8s7VzM4e98B/Azw6iTvudAhI8pqVMWqOlJV01U1PTU1NW4XJUkL9Lm881bg6aqar6r/Bb4M/CrwXJLNAN3yXFd/Dtg2dPxWBpeDJEmrpE/oPwPcmORVSQLcDJwCjgP7uzr7gXu79ePAviRXJtkB7AQe7tG+JGmZNo57YFU9lOSLwKPAeeAx4AhwFXAsye0M3hhu6+qfTHIMeLKrf0dVvdCz/5KkZRg79AGq6k7gzgXFzzM46x9V/zBwuE+bkqTx+USuJDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGtIr9JO8NskXk3wryakkb0pyTZIHkjzVLa8eqn8oyWyS00lu6d99SdJy9D3T/2Pgr6vqF4A3AKeAg8CJqtoJnOi2SbIL2AdcD+wB7k6yoWf7kqRlGDv0k7wGeDPwaYCq+nFVfR/YCxztqh0Fbu3W9wL3VNXzVfU0MAvsHrd9SdLy9TnT/3lgHvjzJI8l+VSSVwPXVdVZgG55bVd/C3Bm6Pi5ruwlkhxIMpNkZn5+vkcXJUnD+oT+RuAG4JNV9Ubgv+gu5SwiI8pqVMWqOlJV01U1PTU11aOLkqRhfUJ/Dpirqoe67S8yeBN4LslmgG55bqj+tqHjtwLP9mhfkrRMY4d+Vf07cCbJ67qim4EngePA/q5sP3Bvt34c2JfkyiQ7gJ3Aw+O2L0lavo09j/8t4PNJXg58G3g/gzeSY0luB54BbgOoqpNJjjF4YzgP3FFVL/RsX5K0DL1Cv6oeB6ZH7Lp5kfqHgcN92pQkjc8nciWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGtI79JNsSPJYkvu67WuSPJDkqW559VDdQ0lmk5xOckvftiVJy7MSZ/ofAk4NbR8ETlTVTuBEt02SXcA+4HpgD3B3kg0r0L4kaYl6hX6SrcDbgU8NFe8FjnbrR4Fbh8rvqarnq+ppYBbY3ad9SdLy9D3T/zjwEeAnQ2XXVdVZgG55bVe+BTgzVG+uK3uJJAeSzCSZmZ+f79lFSdKLxg79JO8AzlXVI0s9ZERZjapYVUeqarqqpqempsbtoiRpgY09jr0JeGeStwGvAF6T5HPAc0k2V9XZJJuBc139OWDb0PFbgWd7tC9JWqaxz/Sr6lBVba2q7Qxu0H6tqt4DHAf2d9X2A/d268eBfUmuTLID2Ak8PHbPJUnL1udMfzF3AceS3A48A9wGUFUnkxwDngTOA3dU1QuXoH1J0iJWJPSr6kHgwW79e8DNi9Q7DBxeiTYlScvnE7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyNihn2Rbkq8nOZXkZJIPdeXXJHkgyVPd8uqhYw4lmU1yOsktKzEASdLS9TnTPw/8XlX9InAjcEeSXcBB4ERV7QROdNt0+/YB1wN7gLuTbOjTeUnS8owd+lV1tqoe7dZ/BJwCtgB7gaNdtaPArd36XuCeqnq+qp4GZoHd47YvSVq+Fbmmn2Q78EbgIeC6qjoLgzcG4Nqu2hbgzNBhc13ZqNc7kGQmycz8/PxKdFGSxAqEfpKrgC8BH66qH16o6oiyGlWxqo5U1XRVTU9NTfXtoiSp0yv0k1zBIPA/X1Vf7oqfS7K5278ZONeVzwHbhg7fCjzbp31J0vL0+fROgE8Dp6rqY0O7jgP7u/X9wL1D5fuSXJlkB7ATeHjc9iVJy7exx7E3Ae8Fvpnk8a7so8BdwLEktwPPALcBVNXJJMeAJxl88ueOqnqhR/uSpGUaO/Sr6u8YfZ0e4OZFjjkMHB63TUlSPz6RK0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkFUP/SR7kpxOMpvk4Gq3L0ktW9XQT7IB+FPg14FdwLuT7FrNPkhSy1b7TH83MFtV366qHwP3AHtXuQ+S1KxU1eo1lrwL2FNVv9Ftvxf4lar64IJ6B4AD3ebrgNNjNrkJ+O6Yx643l8tYLpdxgGNZry6XsfQdx89V1dTCwo09XnAcGVH2knedqjoCHOndWDJTVdN9X2c9uFzGcrmMAxzLenW5jOVSjWO1L+/MAduGtrcCz65yHySpWasd+v8I7EyyI8nLgX3A8VXugyQ1a1Uv71TV+SQfBP4G2AB8pqpOXsIme18iWkcul7FcLuMAx7JeXS5juSTjWNUbuZKkteUTuZLUEENfkhoy8aGf5DNJziV5YpH9SfKJ7msf/jnJDavdx6VawljekuQHSR7vfv5gtfu4FEm2Jfl6klNJTib50Ig6EzEvSxzLpMzLK5I8nOSfurH84Yg6635eljiOiZiTFyXZkOSxJPeN2Leyc1JVE/0DvBm4AXhikf1vA+5n8IzAjcBDa93nHmN5C3DfWvdzCePYDNzQrf8U8C/ArkmclyWOZVLmJcBV3foVwEPAjZM2L0scx0TMyVB/fxf4y1F9Xuk5mfgz/ar6BvAfF6iyF/hsDfwD8Nokm1end8uzhLFMhKo6W1WPdus/Ak4BWxZUm4h5WeJYJkL3u/7PbvOK7mfhJznW/bwscRwTI8lW4O3ApxapsqJzMvGhvwRbgDND23NM6D/azpu6/9ben+T6te7MxSTZDryRwdnYsImblwuMBSZkXrrLCI8D54AHqmoi52UJ44AJmRPg48BHgJ8ssn9F56SF0F/SVz9MiEcZfJ/GG4A/Af5qbbtzYUmuAr4EfLiqfrhw94hD1u28XGQsEzMvVfVCVf0Sg6fhdyd5/YIqEzEvSxjHRMxJkncA56rqkQtVG1E29py0EPqXzVc/VNUPX/xvbVV9FbgiyaY17tZISa5gEJKfr6ovj6gyMfNysbFM0ry8qKq+DzwI7Fmwa2LmBRYfxwTNyU3AO5N8h8G3Dv9aks8tqLOic9JC6B8H3tfdAb8R+EFVnV3rTo0jyU8nSbe+m8H8fW9te/VSXR8/DZyqqo8tUm0i5mUpY5mgeZlK8tpu/ZXAW4FvLai27udlKeOYlDmpqkNVtbWqtjP4WpqvVdV7FlRb0TlZ7W/ZXHFJvsDgTv2mJHPAnQxu7FBVfwZ8lcHd71ngv4H3r01PL24JY3kX8IEk54H/AfZVd3t/nbkJeC/wze66K8BHgZ+FiZuXpYxlUuZlM3A0gz9m9DLgWFXdl+Q3YaLmZSnjmJQ5GelSzolfwyBJDWnh8o4kqWPoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIb8H3S7RWzK50DdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(ypred_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame\n",
    "test_labels['price'] = ypred_test\n",
    "test_labels['price'] = test_labels['price'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>12921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>7174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>9240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>11663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4513</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  price\n",
       "0      7715      2\n",
       "1     13196      2\n",
       "2     13194      2\n",
       "3      4673      2\n",
       "4     11325      2\n",
       "...     ...    ...\n",
       "4144  12921      2\n",
       "4145   7174      2\n",
       "4146   9240      3\n",
       "4147  11663      1\n",
       "4148   4513      3\n",
       "\n",
       "[4149 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(r'./submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
