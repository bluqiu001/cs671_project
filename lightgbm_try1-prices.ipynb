{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train/test data and extract X/Y\n",
    "train_data = pd.read_csv('./train_noclean_prices.csv')\n",
    "test_data = pd.read_csv('./test_noclean_prices.csv')\n",
    "\n",
    "y_train = train_data.loc[:,'price']\n",
    "train_data = train_data.drop(columns='price')\n",
    "num_features = len(train_data.columns)\n",
    "features = list(train_data.columns[2:num_features])\n",
    "X_train = train_data.loc[:,features]\n",
    "\n",
    "features = list(test_data.columns[2:num_features])\n",
    "\n",
    "X_test = test_data.loc[:,features]\n",
    "test_labels = test_data.loc[:,'id']\n",
    "\n",
    "test_labels = test_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1593 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1709 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1829 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2081 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2146 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2213 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2349 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2489 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2633 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2706 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2781 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2856 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2933 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3010 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3089 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3249 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3330 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3413 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3496 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3581 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3666 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3753 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3929 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4109 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4200 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4293 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4386 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4481 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4673 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4770 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4869 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4968 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5069 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5170 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5273 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5376 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5481 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5586 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5693 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5800 tasks      | elapsed: 46.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5909 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6018 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6129 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6240 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6353 tasks      | elapsed: 50.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6466 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6581 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6696 tasks      | elapsed: 53.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6813 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6930 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7049 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7168 tasks      | elapsed: 56.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7289 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7410 tasks      | elapsed: 59.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7533 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7656 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7781 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8033 tasks      | elapsed: 64.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8160 tasks      | elapsed: 65.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8289 tasks      | elapsed: 67.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8418 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8549 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8680 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8813 tasks      | elapsed: 70.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8946 tasks      | elapsed: 71.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9081 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9216 tasks      | elapsed: 73.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9353 tasks      | elapsed: 74.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9490 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9629 tasks      | elapsed: 76.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9768 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9909 tasks      | elapsed: 79.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 79.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "{'subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 0.8, 'reg_alpha': 0.5, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.3, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8} 0.5591362186457881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "#run random grid search with k fold estimator and parallel processing\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 1500],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [10, 15,20,25],\n",
    "    'num_leaves': [10, 20, 30, 40, 50],\n",
    "    'reg_lambda': [0.2, 0.5, 0.8, 1, 1.1],\n",
    "    'reg_alpha' : [0.2, 0.5, 0.8, 1, 1.1], \n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20], \n",
    "    'min_data_in_leaf': [15, 25, 30, 40],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='multiclass', metric='multi_error')\n",
    "rsearch = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_grid, cv=kf, n_iter = 1000, n_jobs = -1, verbose=10)\n",
    "lgb_model = rsearch.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 0.8, 'reg_alpha': 0.5, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.3, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8} 0.5591362186457881\n"
     ]
    }
   ],
   "source": [
    "print(lgb_model.best_params_, lgb_model.best_score_)\n",
    "#THIS IS FOR THE RANDOM SEARCH\n",
    "#print parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5737874097007224\n",
      "0.5340909090909091\n",
      "0.5568181818181818\n",
      "0.5702479338842975\n",
      "0.5609504132231405\n",
      "0.5433884297520661\n",
      "0.5475206611570248\n",
      "0.5578512396694215\n",
      "0.5650826446280992\n",
      "0.5206611570247934\n"
     ]
    }
   ],
   "source": [
    "#run model again and print CV scores \n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    X_train_kf, X_test_kf = X[train],X[test]\n",
    "    y_train_kf, y_test_kf = y[train],y[test]\n",
    "    d_train=lgb.Dataset(X_train_kf, label=y_train_kf)\n",
    "    best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 0.8, 'reg_alpha': 0.5, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.3, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
    "    clf=lgb.train(best_param,d_train )\n",
    "    \n",
    "    y_pred=clf.predict(X_test_kf)\n",
    "    y_pred = [np.argmax(line) for line in y_pred]\n",
    "    print(accuracy_score(y_test_kf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run final model with \"best_param\" as parameters and entire train set\n",
    "X = np.concatenate([X_train], axis= 0)\n",
    "y = np.concatenate([y_train], axis= 0)\n",
    "best_param = {'verbose':-1,'boosting_type':'gbdt',  'objective':'multiclass', 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 0.8, 'reg_alpha': 0.5, 'num_leaves': 30, 'n_estimators': 1500, 'min_split_gain': 0.3, 'min_data_in_leaf': 15, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
    "\n",
    "best_param1 = {'boosting_type':'gbdt',  'objective':'multiclass', 'learning_rate':0.01, 'num_class':5, 'metric':'multi_error','subsample_freq': 20, 'subsample': 0.8, 'reg_lambda': 1.2, 'num_leaves': 40, 'n_estimators': 1000, 'min_split_gain': 0.4, 'min_data_in_leaf': 25, 'max_depth': 20, 'colsample_bytree': 0.7}\n",
    "d_train=lgb.Dataset(X, y)\n",
    "clf=lgb.train(best_param,d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8595186447681025\n"
     ]
    }
   ],
   "source": [
    "y_pred1=clf.predict(X)\n",
    "#print training accuracy \n",
    "y_pred1 = [np.argmax(line) for line in y_pred1]\n",
    "print(accuracy_score(y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test set\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10620062e-15 1.47085792e-01 5.45827415e-01 2.32050743e-01\n",
      "  7.50360502e-02]\n",
      " [1.00248840e-15 7.95201380e-02 3.27910022e-01 4.81130244e-01\n",
      "  1.11439596e-01]\n",
      " [8.74255484e-16 3.07506383e-01 3.98789149e-01 2.39330589e-01\n",
      "  5.43738790e-02]\n",
      " ...\n",
      " [9.69328543e-16 6.52846697e-02 2.20550942e-01 4.42970529e-01\n",
      "  2.71193860e-01]\n",
      " [3.40972928e-16 9.18490803e-01 4.12302714e-02 2.99197712e-02\n",
      "  1.03591548e-02]\n",
      " [1.28477150e-15 1.29044209e-01 4.46131952e-01 2.85289333e-01\n",
      "  1.39534506e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(line) for line in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to dataframe\n",
    "df = pd.DataFrame\n",
    "test_labels['price'] = y_pred\n",
    "\n",
    "test_labels['price'] = test_labels['price'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13196</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>12921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>7174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>9240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>11663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  price\n",
       "0      7715      2\n",
       "1     13196      3\n",
       "2     13194      2\n",
       "3      4673      2\n",
       "4     11325      1\n",
       "...     ...    ...\n",
       "4144  12921      2\n",
       "4145   7174      1\n",
       "4146   9240      3\n",
       "4147  11663      1\n",
       "4148   4513      2\n",
       "\n",
       "[4149 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to csv\n",
    "test_labels.to_csv(r'./submission17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print histogram \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "labels = pd.read_csv('./submission7.csv')\n",
    "y_pred = labels.loc[:,'price']\n",
    "plt.figure()\n",
    "plt.hist(y_pred)\n",
    "plt.title(\"Light GBM Predictions\")\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
